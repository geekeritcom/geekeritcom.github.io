<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Config Github And Gitlab At Same Computer]]></title>
    <url>%2F2019%2F10%2F31%2FJava%2Fvcs%2Fgit_config%2F</url>
    <content type="text"><![CDATA[生成秘钥生成需要的秘钥公钥，这里需要注意的是如果需要同时为github与gitlab生成配置时需要指定文件名称，否则会被覆盖 1ssh-keygen -t rsa -C 'youremail' 上传秘钥将生成的公钥上传至网站ssh配置处 本地机器配置位于用户目录下的.ssh文件夹中，不存在时创建该文件config 123456789101112# gitlab# Host需要指定为自己gitlab的地址Host 192.168.1.102 HostName 192.168.1.102 PreferredAuthentications publickey # 指定对应网站相应的私钥 IdentityFile ~/.ssh/gitlab# githubHost github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa 参考链接GitLab配置ssh key 可以在一台机器上使用GitHub和GitLab吗？ Generating a new SSH key and adding it to the ssh-agent]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>版本控制</tag>
        <tag>SSH</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8中的Optional容器]]></title>
    <url>%2F2019%2F07%2F10%2FJava%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2FJava8%2FOptional%2F</url>
    <content type="text"><![CDATA[Optional作用解决Java中最常见的异常之一：NullPointerException) 创建Optionalempty()创建指定对象的Optional空实例 12345public static&lt;T&gt; Optional&lt;T&gt; empty() &#123; @SuppressWarnings("unchecked") Optional&lt;T&gt; t = (Optional&lt;T&gt;) EMPTY; return t;&#125; of(T value)创建非空值的指定对象的Optional实例 123public static &lt;T&gt; Optional&lt;T&gt; of(T value) &#123; return new Optional&lt;&gt;(value);&#125; ofNullable(T value)创建Optional实例，当指定对象为空值时返回Optional空实例，相当于结合了empty()与of(T value)方法 123public static &lt;T&gt; Optional&lt;T&gt; ofNullable(T value) &#123; return value == null ? empty() : of(value);&#125; 使用案例123456789101112131415161718/** * @author Aaryn * @date 2019/7/9 13:22 */public class OptionalCreateTest &#123; public static void main(String[] args) &#123; Optional&lt;Department&gt; optionalDepartment = Optional.empty(); optionalDepartment.ifPresent(System.out::println); Optional&lt;Department&gt; departmentOptional = Optional.of(new Department()); departmentOptional.ifPresent(System.out::println); Optional&lt;Department&gt; optional = Optional.ofNullable(null); optional.ifPresent(System.out::println); &#125;&#125; 获取Optional中的值get()Optional中不存在该元素时抛出NoSuchElementException 123456public T get() &#123; if (value == null) &#123; throw new NoSuchElementException("No value present"); &#125; return value;&#125; orElse(T other)对象存在时获取对象，不存在时返回指定的对象 123public T orElse(T other) &#123; return value != null ? value : other;&#125; orElseGet(Supplier&lt;? extends T&gt; other)对象存在时获取对象，不存在时使用指定的Supplier创建对象 123public T orElseGet(Supplier&lt;? extends T&gt; other) &#123; return value != null ? value : other.get();&#125; orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier)对象存在时返回对象，不存在时通过指定的exceptionSupplier抛出异常 1234567public &lt;X extends Throwable&gt; T orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) throws X &#123; if (value != null) &#123; return value; &#125; else &#123; throw exceptionSupplier.get(); &#125;&#125; 使用案例1234567891011121314151617181920212223/** * @author Aaryn * @date 2019/7/9 14:30 */public class OptionalGetValueTest &#123; @Data @AllArgsConstructor @NoArgsConstructor private static class Animal &#123; private String name; private String number; &#125; public static void main(String[] args) &#123; Optional&lt;Animal&gt; animal = Optional.empty(); Animal backAnimal = new Animal("dog", "lily"); System.out.println(animal.orElse(backAnimal)); System.out.println(animal.orElseGet(Animal::new)); System.out.println(animal.orElseThrow(() -&gt; new RuntimeException("Animal not exists."))); &#125;&#125; 判断Optional容器中是否存在元素isPresent()元素不存在时返回false，存在时返回true 123public boolean isPresent() &#123; return value != null;&#125; ifPresent(Consumer&lt;? super T&gt; consumer)当元素存在时，将Optional容器中的元素作为指定的consumer的参数执行 1234public void ifPresent(Consumer&lt;? super T&gt; consumer) &#123; if (value != null) consumer.accept(value);&#125; 使用示例12345678910111213141516/** * @author Aaryn * @date 2019/7/9 16:00 */public class OptionalPresentTest &#123; public static void main(String[] args) &#123; Optional&lt;Department&gt; department = Optional.empty(); System.out.println(department.isPresent()); Optional&lt;Department&gt; departmentOptional = Optional.of(new Department()); departmentOptional.ifPresent(System.out::println); &#125;&#125; 操作Optional容器中的元素filter(Predicate&lt;? super T&gt; predicate)Optional容器中的元素符合给定predicate时返回元素，否则返回Optional空实例。 1234567public Optional&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate) &#123; Objects.requireNonNull(predicate); if (!isPresent()) return this; else return predicate.test(value) ? this : empty();&#125; map(Function&lt;? super T, ? extends U&gt; mapper)元素不为空时，将Optional容器中的元素按照给定函数进行映射，否则返回Optional空实例。 12345678public&lt;U&gt; Optional&lt;U&gt; map(Function&lt;? super T, ? extends U&gt; mapper) &#123; Objects.requireNonNull(mapper); if (!isPresent()) return empty(); else &#123; return Optional.ofNullable(mapper.apply(value)); &#125;&#125; flatMap(Function&lt;? super T, Optional&lt;U&gt;&gt; mapper)在我们定义的实体中很可能指定使用Optional容器定义具有级联关系的对象，那么在使用Map操作后返回的类型是Optional&lt;Optional&lt;T value&gt;&gt;类型的参数，这样就无法直接使用Map再进行操作，而使用flatMap可以直接取出Optional级联对象进行操作 12345678public&lt;U&gt; Optional&lt;U&gt; flatMap(Function&lt;? super T, Optional&lt;U&gt;&gt; mapper) &#123; Objects.requireNonNull(mapper); if (!isPresent()) return empty(); else &#123; return Objects.requireNonNull(mapper.apply(value)); &#125;&#125; 使用示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * @author Aaryn * @date 2019/7/9 16:22 */public class OptionalElementTest &#123; @Data @AllArgsConstructor @NoArgsConstructor private static class Animal &#123; /** * 动物昵称 */ private String name; /** * 动物编号 */ private String number; /** * 所属管理员 */ private Optional&lt;ZooManager&gt; zooManager; &#125; @Data @AllArgsConstructor @NoArgsConstructor private static class ZooManager &#123; /** * 管理员姓名 */ private String name; &#125; final static Optional&lt;Animal&gt; ANIMAL = Optional.of(new Animal("dog", "2019564124", Optional.of(new ZooManager("lily")))); public static void main(String[] args) &#123; filterTest(); mapTest(); flatMapTest(); &#125; /** * 找出小狗 */ private static void filterTest() &#123; ANIMAL.filter(x -&gt; "dog".equals(x.getName())) .ifPresent(System.out::println); Optional&lt;Animal&gt; animal = Optional.empty(); animal.filter(Objects::nonNull); &#125; /** * 找出小狗的编号 */ private static void mapTest() &#123; Optional&lt;Animal&gt; animal = ANIMAL.filter(x -&gt; "dog".equals(x.getName())); animal.map(Animal::getNumber).ifPresent(System.out::println); &#125; /** * 找出小狗的管理员姓名 */ private static void flatMapTest() &#123; ANIMAL.filter(x -&gt; "dog".equals(x.getName())) .flatMap(Animal::getZooManager) .map(ZooManager::getName) .ifPresent(System.out::println); &#125;&#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Java8</tag>
        <tag>NPE - Optional</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用集合类介绍之List]]></title>
    <url>%2F2019%2F04%2F01%2FJava%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fcollection%2F%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88%E7%B1%BB%E4%B9%8BList%2F</url>
    <content type="text"><![CDATA[List特点 存储元素有序，可以重复，集合中的元素都有对应的索引 集合中的元素都对应一个整数型的序号记载其在容器中的位置，可以根据序号存取容器中的元素 常用子类ArrayList、LinkedList、Vector 常用方法 方法名称 作用 返回值类型 get(int index) 返回列表中指定位置的元素。 E indexOf(Object o) 返回此列表中指定元素的第一个出现项的索引，如果该列表不包含该元素，则返回-1。 int lastIndexOf(Object o) 返回此列表中指定元素的最后一次出现的索引，如果该列表不包含该元素，则返回-1。 int listIterator() 返回列表中元素的列表迭代器(按适当的顺序)。 ListIterator&lt;E&gt; set(int index, E element) 用指定的元素(可选操作)替换列表中指定位置的元素。 E sort(Comparator&lt;? super E&gt; c) 根据指定比较器所诱导的顺序对该列表进行排序。 void subList(int fromIndex, int toIndex) 返回列表中指定的包含的fromIndex和包含的toIndex之间的部分的视图。 List&lt;E&gt; remove(int index) 移除集合中指定索引的元素 E remove(Object o) 移除集合中的第一个匹配到的指定元素 boolean ArrayList概述首先调用无参构造初始化空的底层对象数组（在首次新增元素时才会创建初始长度为10的对象数组），新增元素时调用add()方法进行元素存储，如果在添加元素时导致底层数组的容量不足会触发底层数组扩容的操作，默认情况下会将数组容量扩容为原来的1.5倍，同时将原来数组中的内容复制到新数组中。 如果能够确定存放元素的大致数量时，建议开发中直接调用带参构造方法指定底层数组的容量，防止集合进行频繁扩容。 因为数组在存储数据时是按顺序存储的，存储数据的内存也是连续的，所以ArrayList的特点就是读取数据比较容易，插入删除数据比较困难。 源码分析构造方法1234567891011121314151617181920212223242526272829// 指定初始Object数组的大小public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125;// 空参构造public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125;// 将指定集合转为ArrayListpublic ArrayList(Collection&lt;? extends E&gt; c) &#123; // 集合转为数组 elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 插入数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public boolean add(E e) &#123; // 检测数组是否需要扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // 数组赋值 elementData[size++] = e; return true;&#125;public void add(int index, E element) &#123; // 判断index是否越界 rangeCheckForAdd(index); // 检测数组是否需要扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // 将index之后的所有数据向后移动一位，为新元素的存放做准备 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 将index位置覆盖为指定值 elementData[index] = element; size++;&#125;// 扩容入口private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;// 计算最小容量private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // DEFAULT_CAPACITY默认数组容量为10 return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code // 判断是否满足扩容条件 最小容量 - Object数组的长度 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;// 数组扩容方法private void grow(int minCapacity) &#123; // overflow-conscious code // 当前数组长度 int oldCapacity = elementData.length; // 新的数组容量 = 老容量 + 老容量/2(1.5倍) int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 删除数据1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 删除指定位置元素public E remove(int index) &#123; // 检测index合法性 rangeCheck(index); modCount++; // 获取要删除的元素 E oldValue = elementData(index); // 将index+1以及之后的元素向前移动一位，覆盖被删除的值 int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); // 将最后一个位置的元素清空 elementData[--size] = null; // clear to let GC do its work return oldValue;&#125;// 删除集合中的指定值public boolean remove(Object o) &#123; // 判断元素是否为空 if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; // 没有匹配元素的情况下返回false return false;&#125;// 快速删除private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; 遍历集合12345678910111213141516171819202122232425262728293031323334353637383940414243// 使用foreach进行集合迭代时删除元素为抛出ConcurrentModificationException异常public static void main(String[] args) &#123; List&lt;Integer&gt; numberList = Arrays.asList(1, 2, 3, 4, 5); ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(numberList); for (Integer integer : list) &#123; if (2 == integer) &#123; list.remove(integer); &#125; &#125;&#125;// Exception in thread "main" java.util.ConcurrentModificationException// 改为使用迭代器进行元素的移除public static void main(String[] args) &#123; List&lt;Integer&gt; numberList = Arrays.asList(1, 2, 3, 4, 5); ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(numberList); Iterator&lt;Integer&gt; iterator = list.iterator(); while (iterator.hasNext())&#123; if (2 == iterator.next())&#123; iterator.remove(); &#125; &#125;&#125;public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; // 修改expectedModCount与modCount一致 expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125;&#125; LinkedList概述链表是一种物理存储单元上非连续，非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。链表由一系列的节点（链表中的每一个元素称为节点）组成，节点可以在运行时动态生成。每个节点包括两部分：一部分是存储数据元素的数据域，另一部分是存储下一个节点地址的指针域。 双向链表是链表的一种，由节点组成，每个数据节点中都有两个指针，分别指向直接后继和直接前驱。 源码分析构造方法1234567public LinkedList() &#123;&#125;public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 插入方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public boolean add(E e) &#123; linkLast(e); return true;&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; // 新创建节点 l前继节点，e（新创建节点）,null final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // 新节点是尾节点 last = newNode; // 判断链表是否有元素 if (l == null) first = newNode; else // 设置原尾节点的后继节点是新节点 l.next = newNode; size++; modCount++;&#125;// 链表指定位置插入元素public void add(int index, E element) &#123; // 检查index的合法性 checkPositionIndex(index); // 当index等于链表大小时表示要将元素插入链表尾部 if (index == size) linkLast(element); else // element 要插入的节点 // node(index) 原index位置节点 linkBefore(element, node(index));&#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; // 原来index位置的前节点pred final Node&lt;E&gt; pred = succ.prev; // 创建新节点 pred(前节点),e(指定插入节点),succ(原节点) final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // 原index位置节点的前继节点变为新节点 succ.prev = newNode; // 判断原节点的前节点是否为空 if (pred == null) // 前节点为空时新节点为链表的第一个节点 first = newNode; else // 修改pred的指针，指向newNode节点 pred.next = newNode; // 链表元素个数增加 size++; // 更改次数增加 modCount++;&#125; 删除方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// 删除指定位置的节点public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125; // 获取index位置的元素节点Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 如果index小于(链表的size/2) // 从前往后找 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; // 从后往前找 Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125;// 删除链表中的指定内容public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125;E unlink(Node&lt;E&gt; x) &#123; // assert x != null; // x 要删除的节点 final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // 判断要删除节点的前继节点是否为空 if (prev == null) &#123; // 头部指向x删除节点的后继节点 first = next; &#125; else &#123; // 删除元素的前继节点指向删除元素的后继节点 prev.next = next; // 清空删除节点x的前继指向 x.prev = null; &#125; // prev &lt;-- x --&gt; next // 删除节点的后继节点为空 if (next == null) &#123; // 尾部指向删除节点的前继节点 last = prev; &#125; else &#123; // 删除节点的后继节点，指向删除节点的前继节点 next.prev = prev; // 清空删除节点x的后继指向 x.next = null; &#125; // 清空x节点 x.item = null; size--; modCount++; return element;&#125; 查找方法1234public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125; ArrayList，LinkedList与Vector的区别相同点都实现了List接口，存储有序可重复的数据 不同点ArrayList采用异步方式处理数据，效率高，是非线程安全的。底层使用Object[]存储 LinkedList底层使用双向链表存储，对于需要频繁插入删除的操作会比ArrayList效率高 VectorVector的推出时间早于ArrayList与LinkedList,处理数据时采用同步方式，属于线程安全的操作，效率低； 虽然Vector属于List接口中线程安全的实现，但是在实际的并发操作中我们还是采用Collections工具类通过其提供的synchronizedList(List&lt;T&gt; list)方法将ArrayList转变为线程安全的集合实现同步操作。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>List</tag>
        <tag>JDK源码解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础数据操纵语言 DML 更新语句]]></title>
    <url>%2F2019%2F03%2F18%2Fdatabase%2FMySQL%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E8%AF%AD%E8%A8%80%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[数据的更新处理大体可以分为插入（INSERT）、删除（DELETE）和更新（UPDATE）三类。 创建测试表1CREATE TABLE ProductIns (product_id CHAR(4) NOT NULL,product_name VARCHAR(100) NOT NULL, product_type VARCHAR(32) NOT NULL,sale_price INTEGER DEFAULT 0,purchase_price INTEGER ,regist_date DATE ,PRIMARY KEY (product_id)); 新增数据syntax12345678910111213141516171819INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] [(col_name [, col_name] ...)] &#123;VALUES | VALUE&#125; (value_list) [, (value_list)] ... [ON DUPLICATE KEY UPDATE assignment_list]INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] SET assignment_list [ON DUPLICATE KEY UPDATE assignment_list]INSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE] [INTO] tbl_name [PARTITION (partition_name [, partition_name] ...)] [(col_name [, col_name] ...)] SELECT ... [ON DUPLICATE KEY UPDATE assignment_list] 基本使用1syntax1INSERT INTO tb_name [(col1,col2,...)] &#123;VALUES | VALUE&#125; (val1,val2...)[,(val1,val2,...)]; eg12345678 -- 插入表的全部字段的两种方式 -- 1.指定全部列名 INSERT INTO ProductIns (product_id, product_name, product_type, sale_price, purchase_price, regist_date) VALUES (&apos;0001&apos;, &apos;T恤衫&apos;, &apos;衣服&apos;, 1000, 500,Now()); -- 2.插入全部列时可以不指定列名，一般在插入全部字段数据时使用此方式 INSERT INTO ProductIns VALUES (&apos;0003&apos;, &apos;牛仔裤&apos;, &apos;衣服&apos;, 900, 600,Now()); -- 插入表的部分字段的数据INSERT INTO ProductIns (product_id, product_name, product_type, sale_price, purchase_price) VALUES (&apos;0002&apos;, &apos;夹克&apos;, &apos;衣服&apos;, 1500, 800); 基本使用2syntax1INSERT INTO tb_name SET col1=val1, col2=val2,... eg1INSERT INTO productins SET product_id=&apos;0005&apos;,product_name=&apos;灯泡&apos;,product_type=&apos;电器&apos;,sale_price=100,purchase_price=78,regist_date=NULL ; 基本使用3syntax1INSERT INTO tb_name SELECT column; eg12345678-- 查询从其他表中查询的数据（需要注意字段类型）INSERT INTO productcopy SELECT * FROM productins;-- 根据商品种类进行汇总的表；CREATE TABLE ProductType (product_type VARCHAR(32) NOT NULL,sum_sale_price INTEGER ,sum_purchase_price INTEGER ,PRIMARY KEY (product_type));-- 将查询到的数据插入表中（可以使用 WHERE, GROUP BY等字句）INSERT INTO ProductType (product_type, sum_sale_price, sum_purchase_price) SELECT product_type, SUM(sale_price), SUM(purchase_price) FROM Product GROUP BY product_type; 插入默认值可以通过两种方式实现，即在INSERT语句的VALUES子句中指定DEFAULT关键字（显式方法），或省略列清单（隐式方法）。 删除数据删除整张表（包括表结构，表索引，表数据等）syntax 1DROP TABLE tb_name； 删除表中数据使用 DELETE删除数据syntax12345DELETE [LOW_PRIORITY] [QUICK] [IGNORE] FROM tbl_name [PARTITION (partition_name [, partition_name] ...)] [WHERE where_condition] [ORDER BY ...] [LIMIT row_count] eg12345-- 删除表中全部数据DELETE FROM tb_name；-- 删除表中的指定数据(可以使用 WHERE字句进行条件筛选，使用 ORDER BY，LIMIT 进行排序与限制) DELETE FROM productins WHERE product_type = &apos;衣服&apos; ORDER BY sale_price DESC LIMIT 1; 使用 TRUNCATE删除表中数据syntax1TRUNCATE [TABLE] tbl_name; TRUNCATE与 DELETE对比 Truncate操作删除并重新创建表，这很重要比逐个删除行要快，特别是对于大型表。 Truncate操作会导致隐式提交，因此无法回滚。 截断操作不会返回数字的有意义的值删除的行。通常的结果是“0行受影响”，应该是这样被解释为“没有信息”。 任何AUTO_INCREMENT值都重置为它的起始值。即使是MyISAM和InnoDB，它们通常也不会重用序列值。 TRUNCATE TABLE语句不会对DELETE触发器调用。 虽然TRUNCATE表类似于DELETE，但它被分类为DDL语句而不是DML语句。 数据更新syntax123UPDATE [LOW_PRIORITY] [IGNORE] table_references SET assignment_list [WHERE where_condition] eg1UPDATE productins SET sale_price=1300,purchase_price=800 WHERE product_id = &apos;0001&apos;; 通常情况下 UPDATE 语句必须要使用 WHERE字句或者使用 LIMIT限制要修改的行数 数据库的安全模式12345-- 查看数据库是否开启安全模式show variables like &apos;SQL_SAFE_UPDATES&apos;;-- 开启数据库的安全模式（关闭时将该值设置为0） SET SQL_SAFE_UPDATES = 1;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>SQL</tag>
        <tag>DML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础数据操纵语言 DML 简单查询]]></title>
    <url>%2F2019%2F03%2F12%2Fdatabase%2FMySQL%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E8%AF%AD%E8%A8%80%E7%AE%80%E5%8D%95%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[什么是 DMLDML（Data Manipulation Language，数据操纵语言）用来查询或者变更表中的记录。 指令 操作 SELECT 查询表中的数据 INSERT 向表中插入新数据 UPDATE 更新表中的数据 DELETE 删除表中的数据 练习所需表基础表12345678CREATE TABLE Product(product_id CHAR(4) NOT NULL, product_name VARCHAR(100) NOT NULL, product_type VARCHAR(32) NOT NULL, sale_price INTEGER , purchase_price INTEGER , regist_date DATE , PRIMARY KEY (product_id)); 基础数据12345678910111213-- 插入数据START TRANSACTION;INSERT INTO Product VALUES (&apos;0001&apos;, &apos;T恤衫&apos;, &apos;衣服&apos;, 1000, 500, &apos;2009-09-20&apos;);INSERT INTO Product VALUES (&apos;0002&apos;, &apos;打孔器&apos;, &apos;办公用品&apos;, 500, 320, &apos;2009-09-11&apos;);INSERT INTO Product VALUES (&apos;0003&apos;, &apos;运动T恤&apos;, &apos;衣服&apos;, 4000, 2800, NULL);INSERT INTO Product VALUES (&apos;0004&apos;, &apos;菜刀&apos;, &apos;厨房用具&apos;, 3000, 2800, &apos;2009-09-20&apos;);INSERT INTO Product VALUES (&apos;0005&apos;, &apos;高压锅&apos;, &apos;厨房用具&apos;, 6800, 5000, &apos;2009-01-15&apos;);INSERT INTO Product VALUES (&apos;0006&apos;, &apos;叉子&apos;, &apos;厨房用具&apos;, 500, NULL, &apos;2009-09-20&apos;);INSERT INTO Product VALUES (&apos;0007&apos;, &apos;擦菜板&apos;, &apos;厨房用具&apos;, 880, 790, &apos;2008-04-28&apos;);INSERT INTO Product VALUES (&apos;0008&apos;, &apos;圆珠笔&apos;, &apos;办公用品&apos;, 100, NULL,&apos;2009-11-11&apos;);COMMIT; SELECTsyntax123456789101112131415161718192021222324SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT] SQL_NO_CACHE [SQL_CALC_FOUND_ROWS] select_expr [, select_expr ...] [FROM table_references [PARTITION partition_list] [WHERE where_condition] [GROUP BY &#123;col_name | expr | position&#125;, ... [WITH ROLLUP]] [HAVING where_condition] [WINDOW window_name AS (window_spec) [, window_name AS (window_spec)] ...] [ORDER BY &#123;col_name | expr | position&#125; [ASC | DESC], ... [WITH ROLLUP]] [LIMIT &#123;[offset,] row_count | row_count OFFSET offset&#125;] [INTO OUTFILE &apos;file_name&apos; [CHARACTER SET charset_name] export_options | INTO DUMPFILE &apos;file_name&apos; | INTO var_name [, var_name]] [FOR &#123;UPDATE | SHARE&#125; [OF tbl_name [, tbl_name] ...] [NOWAIT | SKIP LOCKED] | LOCK IN SHARE MODE]] 基础查询查询表中全部的列syntax 1SELECT * FROM tb_name; 使用 *代替列名不能指定查询后列的显示顺序，查询结果按照定义表时的字段顺序进行排列。 使用 DISTINCT去除重复记录eg 1SELECT DISTINCT product_type FROM product; DISTINCT 关键字只能出现在第一个列名之前 DISTINCT关键字可以用于多列之前，会将多列数据进行组合，并将重复数据合并为一条。 1SELECT DISTINCT product_type,regist_date FROM product; 使用 AS 关键字指定查询列的别名eg 1SELECT product_name AS &quot;商品名称&quot;,sale_price AS &quot;售价&quot;,product_type AS &quot;商品类型&quot; FROM product; 设定汉语别名时需要使用双引号（&quot;）括起来。 使用 WHERE 关键字筛选记录eg 12345-- 查询商品名称为“叉子”的商品信息SELECT product_name AS &quot;商品名称&quot;,sale_price AS &quot;售价&quot;,product_type AS &quot;商品类型&quot; FROM product WHERE product_name = &apos;叉子&apos;;-- 查询售价小于1000的商品SELECT * FROM product WHERE sale_price &lt;= 1000; 比较运算符 运算符 含义 = 相等 &lt;&gt; 不相等 &gt; 大于 &gt;= 大于等于 &lt; 小于 &lt;= 小于等于 eg 12-- 查询日期不等于“2009-09-20”的商品SELECT * FROM product WHERE regist_date &lt;&gt; &apos;2009-09-20&apos;; 逻辑运算符 运算符 含义 NOT 不是 AND 与 OR 或 eg 1SELECT * FROM product WHERE regist_date IS NOT NULL AND product_name = &apos;菜刀&apos;; 练习题question 编写一条 SQL 语句，从 Product（商品）表中选取出“登记日期（regist_date）在 2009 年 4 月 28 日之后”的商品。查询结果要包含 product_name 和 regist_date 两列。 answer 1SELECT product_name AS &quot;商品名称&quot;,regist_date AS &quot;日期&quot; FROM product WHERE regist_date &gt; &apos;2009-04-28&apos;; question 请说出对 Product 表执行如下 3 条 SELECT 语句时的返回结果。 123456789① SELECT * FROM Product WHERE purchase_price = NULL;② SELECT * FROM Product WHERE purchase_price &lt;&gt; NULL;③ SELECT * FROM Product WHERE product_name &gt; NULL; answer 结果全部为空，对包含 NULL值的筛选应该使用 IS NULL 或者 IS NOT NULL question 代码清单 2-22（2-2 节）中的 SELECT 语句能够从 Product 表中取出“销售单价（sale_price）比进货单价（purchase_price）高出 500 日元以上”的商品。请写出两条可以得到相同结果的 SELECT 语句。执行结果如下所示。 执行结果 12345 product_name | sale_price | purchase_price---------------+-------------+---------------- T恤衫 | 1000 | 500 运动T恤 | 4000 | 2800 高压锅 | 6800 | 5000 answer1 1SELECT product_name,sale_price,purchase_price FROM product WHERE product_name = &quot;高压锅&quot; OR product_type = &quot;衣服&quot;; answer2 1SELECT product_name,sale_price,purchase_price FROM product WHERE product_id%2 = 1 LIMIT 3; question 请写出一条 SELECT 语句，从 Product 表中选取出满足“销售单价打九折之后利润高于 100 日元的办公用品和厨房用具”条件的记录。查询结果要包括 produpct_name 列、product_type 列以及销售单价打九折之后的利润（别名设定为 profit）。 提示：销售单价打九折，可以通过 sale_price 列的值乘以 0.9 获得，利润可以通过该值减去 purchase_price 列的值获得。 answer 1SELECT product_name,product_type,(sale_price*0.9-purchase_price) AS &apos;profit&apos; FROM product WHERE sale_price*0.9-purchase_price &gt; 100 AND (product_type = &apos;办公用品&apos; OR product_type = &apos;厨房用具&apos;); 聚合与排序聚合函数 函数名称 操作 COUNT 计算表中的记录数（行数） SUM 计算表中数值列中数据的合计值 AVG 计算表中数值列中数据的平均值 MAX 求出表中任意列中数据的最大值 MIN 求出表中任意列中数据的最小值 COUNTCOUNT函数的结果根据参数的不同而不同。COUNT(*)会得到包含NULL的数据行数，而COUNT(&lt;列名&gt;)会得到NULL之外的数据行数。 eg 1234-- 查询包含NULL值的列SELECT COUNT(purchase_price) FROM product;-- 查询总记录数SELECT COUNT(*) FROM product; SUM计算合计值 eg 1SELECT SUM(sale_price) AS &quot;售价总和&quot; FROM product; AVG计算平均值 eg 1SELECT AVG(sale_price) AS &quot;售价平均值&quot; FROM product; MAX MIN最大值与最小值 eg 1SELECT MAX(sale_price) AS &quot;最高售价&quot;,MIN(sale_price) AS &quot;最低售价&quot; FROM product; 聚合函数会将NULL排除在外。但COUNT(*)例外，并不会排除NULL。 MAX/MIN函数几乎适用于所有数据类型的列。SUM/AVG函数只适用于数值类型的列。 在聚合函数的参数中使用DISTINCT，可以删除重复数据。 分组查询注意点使用聚合函数和GROUP BY子句时需要注意以下4点。 只能写在SELECT子句之中 GROUP BY子句中不能使用SELECT子句中列的别名 GROUP BY子句的聚合结果是无序的 WHERE子句中不能使用聚合函数 聚合键中包含NULL时，在结果中会以“不确定”行（空行）的形式表现出来。 eg 1SELECT product_type, COUNT(*) FROM Product GROUP BY product_type; 常见错误 使用GROUP BY子句时，SELECT子句中不能出现聚合键之外的列名。 在 GROUP BY 子句中写了列的别名（与SQL内部的执行顺序有关） GROUP BY 字句的结果无法进行排序（通过 SELECT语句指定排序方式） 只有SELECT子句和HAVING子句（以及ORDER BY子句）中能够使用聚合函数。 为聚合结果指定条件（HAVING） 使用COUNT函数等对表中数据进行汇总操作时，为其指定条件的不是WHERE子句，而是HAVING子句。 聚合函数可以在SELECT子句、HAVING子句和ORDER BY子句中使用。 HAVING子句要写在GROUP BY子句之后。 1SELECT product_type, COUNT(*) FROM Product GROUP BY product_type HAVING COUNT(*) = 2; WHERE子句用来指定数据行的条件，HAVING子句用来指定分组的条件。 HAVING字句构成要素 常数 聚合函数 GROUP BY字句指定的列名 HAVING 与 WHERE 对比聚合键所对应的条件不应该书写在HAVING子句当中，而应该书写在WHERE子句当中。 二者的作用不同，HAVING 子句是用来指定“组”的条件的。“行”所对应的条件还是应该写在 WHERE 子句当中。 使用 COUNT 函数等对表中的数据进行聚合操作时，DBMS 内部就会进行排序处理。通过 WHERE 子句指定条件时，由于排序之前就对数据进行了过滤，因此能够减少排序的数据量。但 HAVING 子句是在排序之后才对数据进行分组的，因此与在 WHERE 子句中指定条件比起来，需要排序的数据量就会多得多。 对 WHERE 子句指定条件所对应的列创建索引，这样也可以大幅提高处理速度。 排序注意点 使用ORDER BY子句对查询结果进行排序,ORDER BY子句通常写在SELECT语句的末尾。 在ORDER BY子句中列名的后面使用关键字ASC可以进行升序排序，使用DESC关键字可以进行降序排序,默认使用升序进行排列。 ORDER BY子句中可以指定多个排序键。 1SELECT product_id, product_name, sale_price, purchase_price FROM Product ORDER BY sale_price, purchase_price; 排序健中包含NULL时，会在开头或末尾进行汇总。 ORDER BY子句中可以使用SELECT子句中定义的列的别名。 ORDER BY子句中可以使用SELECT子句中未出现的列或者聚合函数。 ORDER BY子句中不能使用列的编号。 使用 HAVING 子句时 SELECT 语句的顺序FROM → WHERE → GROUP BY → HAVING → SELECT → ORDER BY 执行流程 先执行 FROM 字句，然后从表中执行 WHERE 字句找到符合筛选条件的记录，在执行 GROUP BY 函数进行分组，而后执行 HAVING 对分组结果进行聚合过滤，而后使用 ORDER BY 进行排序，然后才去执行 SELECT 操作，最后执行 LIMIT 限制返回记录数 练习题question 请指出下述 SELECT 语句中所有的语法错误。 12345SELECT product_id, SUM(product_name)-- 本SELECT语句中存在错误。 FROM Product GROUP BY product_type WHERE regist_date &gt; &apos;2009-09-01&apos;; answer GROUP BY 字句中不能出现SELECT 字句不包含的列； GROUP BY字句应该位于 WHERE字句之后； question 请编写一条 SELECT 语句，求出销售单价（sale_price 列）合计值是进货单价（purchase_price 列）合计值 1.5 倍的商品种类。执行结果如下所示。 answer 1SELECT product_type,SUM(sale_price) AS &quot;售价总和&quot;,SUM(purchase_price) AS &quot;进价总和&quot; FROM product GROUP BY product_type HAVING SUM(sale_price)/SUM(purchase_price) = 1.5; question 此前我们曾经使用 SELECT 语句选取出了 Product（商品）表中的全部记录。当时我们使用了 ORDER BY 子句来指定排列顺序，但现在已经无法记起当时如何指定的了。请根据下列执行结果，思考 ORDER BY 子句的内容。 执行结果 12345678910product_id | product_name | product_type | sale_price | purchase_price | regist_date-----------+--------------+--------------+-------------+----------------+-----------0003 | 运动T恤 | 衣服 | 4000 | 2800 |0008 | 圆珠笔 | 办公用品 | 100 | | 2009-11-110006 | 叉子 | 厨房用具 | 500 | | 2009-09-200001 | T恤衫 | 衣服 | 1000 | 500 | 2009-09-200004 | 菜刀 | 厨房用具 | 3000 | 2800 | 2009-09-200002 | 打孔器 | 办公用品 | 500 | 320 | 2009-09-110005 | 高压锅 | 厨房用具 | 6800 | 5000 | 2009-01-150007 | 擦菜板 | 厨房用具 | 880 | 790 | 2008-04-28 answer 12-- 按照日期降序，售价升序的方式排列SELECT * FROM product ORDER BY regist_date DESC,sale_price ASC;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>SQL</tag>
        <tag>DML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础之数据定义语言 DDL]]></title>
    <url>%2F2019%2F03%2F11%2Fdatabase%2FMySQL%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89%E8%AF%AD%E8%A8%802019%E5%B9%B43%E6%9C%8811%E6%97%A5%2F</url>
    <content type="text"><![CDATA[SQL基本书写规则 SQL 语句要以分号（;）结尾. SQL 不区分关键字的大小写。 字符串和日期常数需要使用单引号（’）括起来，数字常数无需加注单引号。 SQL 语句的单词之间需使用半角空格或换行符来进行分隔。 数据库名称、表名和列名等可以使用以下三种字符 半角英文字母 半角数字 下划线 _ 数据库名称必须以半角英文字母作为开头,并且不能创建同名称数据库，表或者列。 设定汉语别名时需要使用双引号（&quot;）括起来。 MySQL字符大小写问题 SQL函数与关键字是不区分大小写的 数据库、表名、视图名大小写区分与否取决于底层操作系统与文件系统 存储过程，存储函数以及时间调度器的名字不区分大小写，但是触发器区分大小写 表别名区分大小写 对字段的数据，如果字段类型为 Binary类型，区分大小写，非 Binary不区分大小写 DDL 数据定义语言DDL（Data Definition Language，数据定义语言）用来创建或者删除存储数据用的数据库以及数据库中的表等对象。 关键字 操作 CREATE 创建数据库和表等对象 DROP 删除数据库和表等对象 ALTER 修改数据库和表等对象的结构 创建数据库syntax12345CREATE &#123;DATABASE | SCHEMA&#125; [IF NOT EXISTS] db_name [ ] ...create_specification: [DEFAULT] CHARACTER SET [=] charset_name | [DEFAULT] COLLATE [=] collation_name 参数 作用 db_name 数据库名称 CHARACTER 字符集 COLLATE 排序规则 eg1CREATE DATABASE mydb DEFAULT CHARACTER SET &apos;UTF8&apos;; 删除数据库syntax1DROP &#123;DATABASE | SCHEMA&#125; [IF EXISTS] db_name eg1DROP DATABASE mydb; 修改数据库syntax123456ALTER &#123;DATABASE | SCHEMA&#125; [db_name] alter_specification ...alter_specification: [DEFAULT] CHARACTER SET [=] charset_name | [DEFAULT] COLLATE [=] collation_name 修改数据库表修改表字段字段设置默认值syntax1ALTER TABLE tbl_name ALTER [COLUMN] col_name &#123;SET DEFAULT literal | DROP DEFAULT&#125; eg 1ALTER TABLE students ALTER Tutor SET DEFAULT &apos;Arwin&apos;; 插入新字段syntax12# 可以通过关键词 AFTER 指定该字段位于哪个字段之后ALTER TABLE tbl_name ADD [COLUMN] col_name column_definition [FIRST | AFTER col_name] eg1ALTER TABLE students ADD COLUMN phone VARVHAR(20) NOT NULL AFTER Age; 修改字段名与定义syntax1ALTER TABLE tbl_name CHANGE [COLUMN] old_col_name new_col_name column_definition [FIRST|AFTER col_name] eg 1ALTER TABLE students CHANGE phone user_phone CHAR(11) NOT NULL; 修改字段名称syntax1ALTER TABLE tbl_name RENAME COLUMN old_col_name TO new_col_name eg1ALTER TABLE students RENAME COLUMN user_phone TO phone; 删除字段syntax1ALTER TABLE tbl_name DROP [COLUMN] col_name eg1ALTER TABLE students DROP COLUMN phone; 修改表结构更改表名syntax1ALTER TABLE tbl_name RENAME [TO|AS] new_tbl_name eg1ALTER TABLE students RENAME TO student; 修改存储引擎syntax1ALTER TABLE tbl_name ENGINE [=] engine_name eg1ALTER TABLE student RNGINE = MyISAM; 指定排序标准的字段syntax1ALTER TABLE tbl_name [DEFAULT] COLLATE [=] collation_name 转换字符集及排序规则syntax1ALTER TABLE tbl_name [DEFAULT] CHARACTER SET [=] charset_name eg1ALTER TABLE student CHARACTER SET = UTF8; 创建数据库表第一种方式syntax1234CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name (create_definition,...) [table_options] [partition_options] 1234567891011121314create_definition: col_name column_definition | [CONSTRAINT [symbol]] PRIMARY KEY [index_type] (key_part,...) [index_option] ... | &#123;INDEX|KEY&#125; [index_name] [index_type] (key_part,...) [index_option] ... | [CONSTRAINT [symbol]] UNIQUE [INDEX|KEY] [index_name] [index_type] (key_part,...) [index_option] ... | &#123;FULLTEXT|SPATIAL&#125; [INDEX|KEY] [index_name] (key_part,...) [index_option] ... | [CONSTRAINT [symbol]] FOREIGN KEY [index_name] (col_name,...) reference_definition | CHECK (expr) 123456789101112131415161718192021222324252627282930313233table_option: # 自动增长值从几开始 AUTO_INCREMENT [=] value | AVG_ROW_LENGTH [=] value # 默认字符集 | [DEFAULT] CHARACTER SET [=] charset_name # 是否校验表，每次对表的操作都会触发，系统开销较大 | CHECKSUM [=] &#123;0 | 1&#125; | [DEFAULT] COLLATE [=] collation_name # 添加表注释 | COMMENT [=] &apos;string&apos; | COMPRESSION [=] &#123;&apos;ZLIB&apos;|&apos;LZ4&apos;|&apos;NONE&apos;&#125; | CONNECTION [=] &apos;connect_string&apos; # 数据目录 | 索引目录 | &#123;DATA|INDEX&#125; DIRECTORY [=] &apos;absolute path to directory&apos; # 延迟键写入 | DELAY_KEY_WRITE [=] &#123;0 | 1&#125; | ENCRYPTION [=] &#123;&apos;Y&apos; | &apos;N&apos;&#125; | ENGINE [=] engine_name | INSERT_METHOD [=] &#123; NO | FIRST | LAST &#125; | KEY_BLOCK_SIZE [=] value | MAX_ROWS [=] value | MIN_ROWS [=] value | PACK_KEYS [=] &#123;0 | 1 | DEFAULT&#125; | PASSWORD [=] &apos;string&apos; # 表格式 | ROW_FORMAT [=] &#123;DEFAULT|DYNAMIC|FIXED|COMPRESSED|REDUNDANT|COMPACT&#125; | STATS_AUTO_RECALC [=] &#123;DEFAULT|0|1&#125; | STATS_PERSISTENT [=] &#123;DEFAULT|0|1&#125; | STATS_SAMPLE_PAGES [=] value # 文件存储位置 &#123;DISK | MEMEORY | DEFAULT&#125; | TABLESPACE tablespace_name | UNION [=] (tbl_name[,tbl_name]...) eg1CREATE TABLE students (SID INT UNSIGNED AUTO_INCREMENT NOT NULL UNIQUE KEY,Name CHAR(30) NOT NULL,Age TINYINT UNSIGNED NOT NULL,Gender ENUM (&apos;F&apos;,&apos;M&apos;) NOT NULL,Tutor CHAR(30)); 第二种方式根据现有的表记录填充数据，并不会完全复制表结构 syntax123456CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name [(create_definition,...)] [table_options] [partition_options] [IGNORE | REPLACE] [AS] query_expression eg1CREATE TABLE students2 select * from students; 表数据 表结构 第三种方式根据现有表复制表结构 syntax12CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name &#123; LIKE old_tbl_name | (LIKE old_tbl_name) &#125; eg1CREATE TABLE students3 LIKE students; 表数据 表结构 字段的定义：字段名、类型和类型修饰符 键、约束或者索引 PRIMARY KEY 主键 UNIQUE KEY 唯一键 FOREIGN KEY 外键 键本身就是约束，主键非空唯一 键本身都是索引，但是索引不一定是键 查看数据库相关信息1234567891011121314# 查看数据库列表SHOW DATABASES; # 切换到数据库use DATABASE;# 查看某张表的表结构DESC tb_name;# 查看存储引擎SHOW ENGINES;# 查看表的状态SHOW TABLE STATUS LIKE &apos;TABLE_NAME&apos;\G# 查看表索引SHOW INDEXS FROM TABLE_NAME# 查看支持的排序规则SHOW COLLATION; 存储引擎的存储表方式区别MyISAM每表有三个文件，位于数据库目录中 tb_name.frm:表结构定义 tb_name.MYD数据文件 tb_name.MYI：索引文件 InnoDB两种存储方式 默认存储方式每表一个独立文件和一个多表共享的文件 tb_name.frm:表结构的定义，位于数据库目录中 ibdata#:共享的表空间文件，默认位于数据目录(datadir指向的目录) 独立的表空间此方式有利于表迁移与维护 tb_name.frm:每表有一个表结构文件 tb_name.ibd:一个独有的表空间文件 练习练习题1创建 shop 数据库1CREATE DATABASE IF NOT EXISTS shop DEFAULT CHARACTER SET &apos;UTF8&apos;; 创建 product 表12345678CREATE TABLE Product(product_id CHAR(4) NOT NULL, product_name VARCHAR(100) NOT NULL, product_type VARCHAR(32) NOT NULL, sale_price INTEGER , purchase_price INTEGER , regist_date DATE , PRIMARY KEY (product_id)); 向 Product 表中新增测试列1ALTER TABLE Product ADD COLUMN insert_column_test VARCHAR(100) NOT NULL DEFAULT &apos;test&apos;; 新增列名为 insert_column_test 约束为 NOT NULL 默认值为 test 删除新增的测试列1ALTER TABLE Product DROP COLUMN insert_column_test; 变更表名为 Product11ALTER TABLE Product RENAME TO Product1; 删除新建的数据库1DROP DATABASE shop; 练习题2创建表编写一条 CREATE TABLE 语句，用来创建一个包含表 1-A 中所列各项的表 Addressbook（地址簿），并为 regist_no（注册编号）列设置主键约束。 列的含义 列的名称 数据类型 约束 注册编号 regist_no 整数型 不能为 NULL、主键 姓名 name 可变长字符串型（长度为 128 类） 不能为 NULL 住址 address 可变长字符串类型（长度为 256） 不能为 NULL 电话号码 tel_no 定长字符串类型（长度为 10） 邮箱地址 mail_address 定长字符串类型（长度为 20） 1CREATE TABLE address_book (regist_no INTEGER NOT NULL PRIMARY KEY,name VARCHAR(128) NOT NULL COMMENT &apos;姓名&apos;,address VARCHAR(256) NOT NULL COMMENT &apos;住址&apos;,tel_no CHAR(10) COMMENT &apos;电话号码&apos;,mail_address CHAR(20) COMMENT &apos;邮箱地址&apos;); 修改表假设在创建练习中的 Addressbook 表时忘记添加如下一列 postal_code（邮政编码）了，请把此列添加到 Addressbook 表中。 列名 ：postal_code 数据类型：定长字符串类型（长度为 8） 约束 ：不能为 NULL 1ALTER TABLE address_book ADD COLUMN postal_code CHAR(8) NOT NULL COMMENT &apos;邮政编码&apos;; 删除表编写 SQL 语句来删除 Addressbook 表。 1DROP TABLE address_book;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java常用集合之Map]]></title>
    <url>%2F2019%2F03%2F11%2FJava%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fcollection%2F%E5%B8%B8%E7%94%A8%E9%9B%86%E5%90%88%E4%B9%8BMap%2F</url>
    <content type="text"><![CDATA[Map接口存储双列数据，保存key-value关联数据 key 无序的不可重复的使用Set存储所有的key value无序的可重复的使用collection存储所有的value 一个键值对构成一个Entry对象 Map中的entry 无序的不可重复的，使用Set存储所有的entry 常用方法 名称 作用 返回值 containsKey(Object key) 如果此映射包含指定键的映射，则返回true。 boolean containsValue(Object value) 如果此映射将一个或多个键映射到指定值，则返回true。 boolean entrySet() 返回此映射中包含的映射的集合视图。 Set&lt;Map.Entry&lt;K,V&gt;&gt; get(Object key) 返回指定键映射到的值，如果该映射不包含键的映射，则返回null。 V put(K key, V value) 将指定值与此映射中的指定键关联 V remove(Object key) 如果键存在，则从该映射中删除键的映射 V replace(K key, V value) 仅当指定键的项当前映射到某个值时，才替换该项。 V size() 返回此映射中键值映射的数目。 int values() 返回此映射中包含的值的集合视图。 Collection&lt;V&gt; keySet() 返回此映射中包含的键的集合视图。 Set&lt;K&gt; 常用子类HashMap，TreeMap,LinkedHashMap，HashTable等 HashMapHashMap的键如果使用自定义的类，那么自定义的类要求必须重写equals()与hashCode()方法 底层实现原理JDK7在实例化之后底层创建了一个长度为16的一维数组entry[] table; 首先调用键所在类的hashCode()计算键的哈希值，此哈希值经过某种算法后，得到entry在数组中的存放位置。 如果该位置上数据为空，那么entry添加成功 如果该位置的数据不为空，则去比较该entry的键与已存在键的哈希值 ​ 如果键的哈希值与已存在的键的哈希值不同，那么entry添加成功 ​ 如果键的哈希值与某一个数据的哈希值相同时，继续调用键所在类的equals()方法 ​ 当equals()方法返回false时则entry添加成功 ​ 当equals()方法返回true时使用新添加entry的值替换原有的值，此时的put操作类似于修改原有键值对。 在添加数据的过程中会涉及到扩容问题，当超出临界值（数组容量*负载因子）并且需要存放元素的位置非空时发生扩容。默认扩容方式为扩容为原来的2倍，并将原有数据重新计算位置后存放。 JDK8在创建实例时没有创建数组，而是在首次put操作时底层才会进行数组的创建 jdk7的底层结构是数组+链表 jdk8的底层结构是数组+链表+红黑树 当数组的某一个索引位置上的元素以链表形式存在的数据个数大于8并且当前数组的长度大于16时，此时该索引位置上的所有数据改为使用红黑树进行存储。 源码解析 构造方法12345678910111213141516171819202122232425262728// 指定hashMap的初始化容量以及负载因子的大小public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;// 指定hashMap的初始化容量public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;// 空参构造public HashMap() &#123; // 负载因子赋值0.75f this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; 指定初始化容量以及负载因子构造 123456789101112131415161718192021222324public HashMap(int initialCapacity, float loadFactor) &#123; // 判断初始化容量参数合法性 if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); // 初始化容量超出最大值时设置为最大值 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 负载因子合法性检测 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;// 求出2的n次方 &gt;= initialCapacitystatic final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 参数为Map的构造 1234567891011121314151617181920212223242526272829final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; // 传入集合的大小 int s = m.size(); if (s &gt; 0) &#123; // 判断table数组是否为空 if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) // 扩容 resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125;// 获取key的hash值static final int hash(Object key) &#123; int h; // 对象的hashCode值 ^ 对象的hashCode值的高位（前16位） // 目的 提高hash的随机性 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; put()方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public V put(K key, V value) &#123; // 根据传入的key计算hashCode值 return putVal(hash(key), key, value, false, true);&#125;/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 判断table数组是否为空或者长度为0 if ((tab = table) == null || (n = tab.length) == 0) // 初始化table n = (tab = resize()).length; // i 就是元素在table数组中存储的位置 // (n - 1) &amp; hash 本质就是取余运算，目的在于优化计算速度 // 该操作是判断需要存放的数组该位置是否为空 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 创建节点，直接存放到计算出来的tab[i]位置 tab[i] = newNode(hash, key, value, null); else &#123; // tab[i]有元素的情况 Node&lt;K,V&gt; e; K k; // hash值相同的情况 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 判断是否是树结构，JDK1.8 红黑树优化方案 else if (p instanceof TreeNode) // 基于红黑树的插入逻辑 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 链表插入元素 for (int binCount = 0; ; ++binCount) &#123; // 判断p的下一个元素是否为空 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 判断当前链表的数量是否大于树结构的阈值 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 转换结构，链表-&gt;红黑树（优化查询性能） treeifyBin(tab, hash); break; &#125; // 如果当前链表包含要插入的值，结束遍历 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 判断插入的值是否存在于hashMap中 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; // 修改次数+1 ++modCount; // 判断当前数组大小是否大于阈值 if (++size &gt; threshold) // 扩容 resize(); afterNodeInsertion(evict); return null;&#125; 扩容方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192final Node&lt;K,V&gt;[] resize() &#123; // 数组初始值 Node&lt;K,V&gt;[] oldTab = table; // 扩容前的变量初始化 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; // 扩容后的变量初始化 int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 老容量达到最大容量时不再进行扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 老容量*2=新容量 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; // 负载因子*初始容量=阈值 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 准备重新对元素进行定位 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; // 获取第j个位置的元素 if ((e = oldTab[j]) != null) &#123; // 清空原数组 oldTab[j] = null; // 判断原有j的位置上是否有元素 if (e.next == null) // 重新计算位置进行元素保存 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 红黑树拆分 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; // 遍历链表，将链表节点按照顺序进行分组 next = e.next; // 计算原有元素在扩容后还在原位置 if ((e.hash &amp; oldCap) == 0) &#123; // old链表添加到一组 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 计算原有元素在扩容后不在原位置 else &#123; // new链表添加到一组 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; // 原位置j+原容量 = 新位置 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; remove()方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;// final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; // 元素要存储的位置p (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; // hash没有冲突的情况 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 定位要删除的节点node node = p; // 有冲突，在同一个位置上不只是一个元素 else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) // 红黑树定位删除元素 node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; // 链表定位删除元素 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // node要删除的元素 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) // 红黑树删除节点 ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) // 链表删除节点 tab[index] = node.next; else // 数组中p位置的对象的下一个元素 = 要删除的元素的下一个元素 p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; LinkedHashMap保证在遍历元素时可以按照添加的顺序实现遍历，原因在于在原有的HashMap底层结构基础上添加了一对指针，指向前一个与后一个元素，对于频繁的遍历操作效率高于HashMap。 TreeMap保证按照添加的key-value对进行排序，实现排序遍历。考虑key的自然排序或者定制排序。 添加的键必须是同一类创建的对象，因为要按照键进行排序 HashTableproperties常用来处理配置文件，key与value都是String类型 HashMap 与 HashTable的区别HashTable的推出时间早于 HashMap，采用同步处理数据的方式，属于线程安全的操作，效率低，并且不允许设置映射的键值为null；而HashMap异步处理数据，属于线程非安全的操作，效率高，允许将键值设置为null。 Iterator输出的问题Map集合利用Iterator输出的步骤 利用Map接口的entrySet()方法将Map集合转换为Set集合，泛型是Map.Entry&lt;K,V&gt; 利用Set集合的Iterator()方法将集合进行输出 每次Iterator循环取出的都是Map.Entry接口对象，利用此对象能够进行key与value的取出 简单示例 123456789101112public static void main(String[] args) &#123; Map&lt;String,Integer&gt; stringMap = new HashMap&lt;&gt;(16); stringMap.put("1",1); stringMap.put("2",2); stringMap.put("3",3); Set&lt;Map.Entry&lt;String, Integer&gt;&gt; entries = stringMap.entrySet(); Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; iterator = entries.iterator(); while (iterator.hasNext())&#123; Map.Entry&lt;String, Integer&gt; next = iterator.next(); System.out.println("键：" + next.getKey() + "值：" + next.getValue()); &#125; &#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Map - HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thread API详细介绍]]></title>
    <url>%2F2019%2F03%2F11%2FJava%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fthread%2FThread%20API%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[构造方法无参构造通过Thread的无参构造创建线程对象Thread，默认有一个线程名，以Thread-开头，从0开始计数 123public Thread() &#123; init(null, null, "Thread-" + nextThreadNum(), 0);&#125; 线程名称通过Thread的构造方法为线程指定名称 123public Thread(String name) &#123; init(null, null, name, 0);&#125; Runnable通过Thread的构造方法给Thread设置逻辑执行单元 123public Thread(Runnable target) &#123; init(null, target, "Thread-" + nextThreadNum(), 0);&#125; Runnable与线程名称通过Thread的构造方法同时给Thread设置逻辑单元以及线程的名称 123public Thread(Runnable target, String name) &#123; init(null, target, name, 0);&#125; 线程组与Runnable通过Thread的构造方法同时给Thread设置线程组以及逻辑单元 123public Thread(ThreadGroup group, Runnable target) &#123; init(group, target, "Thread-" + nextThreadNum(), 0);&#125; 线程组与线程名称通过Thread的构造方法同时给Thread设置线程组以及线程名称 123public Thread(ThreadGroup group, String name) &#123; init(group, null, name, 0);&#125; 线程组，Runnable与线程名称通过Thread的构造方法同时给Thread设置线程组、逻辑单元以及线程名称 123public Thread(ThreadGroup group, Runnable target, String name) &#123; init(group, target, name, 0);&#125; 线程组，Runnable与线程名称以及线程栈大小通过Thread的构造方法设置线程的stacksize，代表着该线程占用的stack的大小。 如果没有指定stacksize的大小，默认是0，0表示会忽略该参数。 该参数会被JNI函数调用，需要注意的是该参数在一些平台有效，在一些平台则无效。 123public Thread(ThreadGroup group, Runnable target, String name, long stackSize) &#123; init(group, target, name, stackSize);&#125; 注意点JVM栈的大小是固定的，如果调大了某个线程的栈的大小，那么对于JVM来说，可分配给其他线程的栈内存就会减少，那么创建的线程数自然也会减少 如果在构造Thread的时候没有传递Runnable并且也没有复写Thread类中的run()方法，该调用线程的start()方法时不会执行任何操作；如果传递了Runnable接口的实例，或者重写了Thread类中的run()方法，那么调用start()方法就会执行该方法的逻辑单元。 如果构造线程对象时未传入ThreadGroup，Thread会默认获取父线程的ThreadGroup作为该线程的ThreadGroup，此时子线程与父线程位于同一个ThreadGroup中。 守护线程设置线程为守护线程。当JVM中运行的唯一线程都是守护线程时，Java虚拟机将退出。 注意当线程启动之后就不能再去设置线程为守护线程否则会抛出异常 12345678public final void setDaemon(boolean on) &#123; checkAccess(); // 检查线程的当前状态 if (isAlive()) &#123; throw new IllegalThreadStateException(); &#125; daemon = on;&#125; 判断当前线程是否为守护线程123public final boolean isDaemon() &#123; return daemon;&#125; 使用场景当进行长连接的时候需要不断的通过发送心跳包来保证连接的可用性，此时去检查连接可用性的线程可以设置为守护线程，这样做的原因是如果连接线程已经结束了，我们需要去通知检查线程或者手动停止线程，但是线程的stop方法已经被标记为了Deprecated，调用stop方法是不合适的，而把检查状态的线程设置为守护线程好处是在连接线程挂掉的情况下不会造成JVM由于连接 线程不断报错而无法停止，浪费系统资源。 线程基本信息线程名称设置线程名称1234567891011public final synchronized void setName(String name) &#123; checkAccess(); if (name == null) &#123; throw new NullPointerException("name cannot be null"); &#125; this.name = name; if (threadStatus != 0) &#123; setNativeName(name); &#125;&#125; 获取线程名称没有显示指定线程名称的情况下是从Thread-0开始 123public final String getName() &#123; return name;&#125; 线程名称案例123456789101112131415161718192021222324252627282930313233/** * @author Aaryn * @date 2019/7/16 18:34 */public class CreateThread &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(); t1.start(); Thread t2 = new Thread(); t2.start(); /* * 执行结果 * Thread-0 * Thread-1 */ System.out.println(t1.getName()); System.out.println(t2.getName()); Thread t3 = new Thread("T-name"); Thread t4 = new Thread(() -&gt; &#123; System.out.println("do something."); &#125;); /* * 执行结果 * T-name * Thread-2 */ System.out.println(t3.getName()); System.out.println(t4.getName()); &#125;&#125; 线程ID获取线程的ID是在JVM启动后线程数开始进行自增操作 123public long getId() &#123; return tid;&#125; 获取当前线程返回对当前正在执行的线程对象的引用。 1public static native Thread currentThread(); 获取线程所属线程组注意如果当前线程已经处于“死亡”状态，该方法将返回null 123public final ThreadGroup getThreadGroup() &#123; return group;&#125; 线程优先级获取线程的优先级123public final int getPriority() &#123; return priority;&#125; 设置线程的优先级注意设置优先级只是代表该线程获得CPU调度的几率会比较高，并不保证一定能够优先执行 123456789101112131415public final void setPriority(int newPriority) &#123; ThreadGroup g; checkAccess(); // 检查参数的合法性，最大优先级为10，最小优先级为1 if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) &#123; throw new IllegalArgumentException(); &#125; // 如果线程组不为空的情况下，优先级会被设置为线程组的优先级 if((g = getThreadGroup()) != null) &#123; if (newPriority &gt; g.getMaxPriority()) &#123; newPriority = g.getMaxPriority(); &#125; setPriority0(priority = newPriority); &#125;&#125; 堆栈跟踪将当前线程的堆栈跟踪打印到标准错误流。此方法仅用于调试。 123public static void dumpStack() &#123; new Exception("Stack trace").printStackTrace();&#125; 检查权限123456public final void checkAccess() &#123; SecurityManager security = System.getSecurityManager(); if (security != null) &#123; security.checkAccess(this); &#125;&#125; 类加载器获取线程的类加载器返回此Thread的上下文ClassLoader。 上下文ClassLoader由线程的创建者提供，供加载类和资源时在此线程中运行的代码使用。如果未设置，则默认为父线程的ClassLoader上下文。 原始线程的上下文ClassLoader通常设置为用于加载应用程序的类加载器。 12345678910public ClassLoader getContextClassLoader() &#123; if (contextClassLoader == null) return null; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; ClassLoader.checkClassLoaderPermission(contextClassLoader, Reflection.getCallerClass()); &#125; return contextClassLoader;&#125; 设置线程的类加载器1234567public void setContextClassLoader(ClassLoader cl) &#123; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; sm.checkPermission(new RuntimePermission("setContextClassLoader")); &#125; contextClassLoader = cl;&#125; 断言线程是否拥有某对象监视锁当且仅当当前线程在指定对象上保存监视器锁时返回true 1public static native boolean holdsLock(Object obj); 获取堆栈信息返回表示此线程的堆栈转储的堆栈跟踪元素数组如果此线程尚未启动，已启动但尚未安排由系统运行或已终止，则此方法将返回零长度数组。 如果返回的数组长度非零，那么数组的第一个元素表示堆栈的顶部，这是序列中最近的方法调用。数组的最后一个元素表示堆栈的底部，这是序列中最远的方法调用。 1234567891011121314151617181920212223242526public StackTraceElement[] getStackTrace() &#123; if (this != Thread.currentThread()) &#123; // check for getStackTrace permission SecurityManager security = System.getSecurityManager(); if (security != null) &#123; security.checkPermission( SecurityConstants.GET_STACK_TRACE_PERMISSION); &#125; // optimization so we do not call into the vm for threads that // have not yet started or have terminated if (!isAlive()) &#123; return EMPTY_STACK_TRACE; &#125; StackTraceElement[][] stackTraceArray = dumpThreads(new Thread[] &#123;this&#125;); StackTraceElement[] stackTrace = stackTraceArray[0]; // a thread that was alive during the previous isAlive call may have // since terminated, therefore not having a stacktrace. if (stackTrace == null) &#123; stackTrace = EMPTY_STACK_TRACE; &#125; return stackTrace; &#125; else &#123; // Don't need JVM help for current thread return (new Exception()).getStackTrace(); &#125;&#125; 返回所有活动线程的堆栈跟踪映射。映射键是线程，每个映射值都是StackTraceElement数组，表示相应Thread的堆栈转储。返回的堆栈跟踪采用为getStackTrace方法指定的格式。调用此方法时，线程可能正在执行。每个线程的堆栈跟踪仅表示快照，并且可以在不同时间获得每个堆栈跟踪。如果虚拟机没有关于线程的堆栈跟踪信息，则将在映射值中返回零长度数组。 1234567891011121314151617181920212223public static Map&lt;Thread, StackTraceElement[]&gt; getAllStackTraces() &#123; // check for getStackTrace permission SecurityManager security = System.getSecurityManager(); if (security != null) &#123; security.checkPermission( SecurityConstants.GET_STACK_TRACE_PERMISSION); security.checkPermission( SecurityConstants.MODIFY_THREADGROUP_PERMISSION); &#125; // Get a snapshot of the list of all threads Thread[] threads = getThreads(); StackTraceElement[][] traces = dumpThreads(threads); Map&lt;Thread, StackTraceElement[]&gt; m = new HashMap&lt;&gt;(threads.length); for (int i = 0; i &lt; threads.length; i++) &#123; StackTraceElement[] stackTrace = traces[i]; if (stackTrace != null) &#123; m.put(threads[i], stackTrace); &#125; // else terminated so we don't put it in the map &#125; return m;&#125; 获取线程状态1234public State getState() &#123; // get current thread state return sun.misc.VM.toThreadState(threadStatus);&#125; join()API1234567/* 线程join的三种方式 */// 等待线程死亡,类似于调用第二个方法指定等待时间为0毫秒public final void join() throws InterruptedException// 等待线程死亡（等待时间为指定毫秒数）public final void join(long millis) throws InterruptedException// 等待线程死亡（等待时间为指定毫秒数+纳秒数）public final void join(long millis,int nanos) throws InterruptedException 使用示例123456789101112131415161718192021222324/** * @author Aaryn * @date 2019/7/17 14:01 */public class ThreadJoin &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; IntStream.range(0, 1000) .forEach(i -&gt; System.out.println(Thread.currentThread().getName() + "--&gt;" + i)); &#125;); Thread t2 = new Thread(() -&gt; &#123; IntStream.range(0, 1000) .forEach(i -&gt; System.out.println(Thread.currentThread().getName() + "--&gt;" + i)); &#125;); t1.start(); t2.start(); t1.join(); t2.join(); // 程序会等到t1,t2线程全部执行完成才会继续执行主线程中的方法，并且t1,t2线程会交替执行 IntStream.range(0, 1000) .forEach(i -&gt; System.out.println(Thread.currentThread().getName() + "--&gt;" + i)); &#125;&#125; 中断线程概述如果在调用Object类的wait（），wait（long）或wait（long，int）方法，或者join（），join（long），join（long，int），sleep（long）或sleep（long，int）方法，然后它的中断状态将被清除，它将收到InterruptedException。 测试当前线程是否已被中断。类方法此方法清除线程的中断状态。换句话说，如果要连续两次调用此方法，则第二次调用将返回false（除非当前线程在第一次调用已清除其中断状态之后且在第二次调用之前检查它时再次中断）。线程中断被忽略，因为在中断时线程不活动将被此方法反映返回false。 123public static boolean interrupted() &#123; return currentThread().isInterrupted(true);&#125; 实例方法不重置线程中断状态。 123public boolean isInterrupted() &#123; return isInterrupted(false);&#125; 打断线程123456789101112131415// 打断当前线程public void interrupt() &#123; if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; if (b != null) &#123; interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; &#125; &#125; // 调用本地方法打断线程 interrupt0();&#125; 对interrupted()方法要设计成类方法与实例方法的理解当我们直接在创建线程时覆写run方法，相当于使用继承Thread类的方式创建线程，该线程属于Thread类的实例，可以直接调用interrupted()实例方法；但是如果在创建线程时将Runnable接口的实现作为参数传递时，Runnable的实现属于Thread中的匿名内部类，是不可以直接调用实例方法的，所以只能通过Thread的静态方法interrupted()来获取当前线程的中断状态。 使用示例12345678910111213141516171819202122232425262728293031323334/** * @author Aaryn * @date 2019/7/17 15:38 */public class ThreadInterrupt2 &#123; public static void main(String[] args) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; // 可以直接使用Thread类的实例方法查看当前线程的中断状态 System.out.println("t1 interrupt state is " + isInterrupted()); &#125; &#125;; t1.start(); Thread t2 = new Thread(() -&gt; &#123; // 需要调用Thread类中的静态方法查看当前线程的中断状态 System.out.println("t2 interrupt state is " + Thread.interrupted()); &#125;); t2.start(); t2.interrupt(); // 打断当前线程 Thread.currentThread().interrupt(); // 调用Thread的静态方法interrupted后会清除线程的中断状态， // 所以第二次打印Thread的中断状态为false System.out.println(Thread.interrupted()); System.out.println(Thread.interrupted()); &#125;&#125; 线程yield()向调度程序提示当前线程是否愿意产生其当前使用的处理器。调度程序可以忽略此提示。 Yield是一种启发式尝试，用于改善线程之间的相对进展，否则会过度利用CPU。 它的使用应与详细的分析和基准测试相结合，以确保它实际上具有所需的效果。 使用这种方法很少是合适的。它可能对调试或测试目的很有用，它可能有助于重现因竞争条件而产生的错误。 在设计并发控制结构（例如java.util.concurrent.locks包中的结构）时，它也可能很有用。 1public static native void yield(); 线程休眠概述导致当前正在执行的线程休眠（暂时停止执行）指定的毫秒数，具体取决于系统计时器和调度程序的精度和准确性。该线程不会失去任何监视器的所有权。 休眠指定的毫秒数1public static native void sleep(long millis) throws InterruptedException; 休眠指定的毫秒数+纳秒数1234567891011121314public static void sleep(long millis, int nanos) throws InterruptedException &#123; if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (nanos &lt; 0 || nanos &gt; 999999) &#123; throw new IllegalArgumentException( "nanosecond timeout value out of range"); &#125; if (nanos &gt;= 500000 || (nanos != 0 &amp;&amp; millis == 0)) &#123; millis++; &#125; sleep(millis);&#125; 活跃线程判断线程活跃状态线程启动后并且还没有死亡就属于活跃状态 1public final native boolean isAlive(); 获取活跃线程数返回当前线程的线程组及其子组中活动线程数的估计值。递归迭代当前线程的线程组中的所有子组。 返回的值只是一个估计值，因为当此方法遍历内部数据结构时，线程数可能会动态更改，并且可能会受到某些系统线程的影响。此方法主要用于调试和监视目的。 123public static int activeCount() &#123; return currentThread().getThreadGroup().activeCount();&#125; 返回此线程所属的线程组。如果此线程已死（已停止），则此方法返回null。 123public final ThreadGroup getThreadGroup() &#123; return group;&#125; 获取活跃线程 将当前线程的线程组及其子组中的每个活动线程复制到指定的数组中。 此方法只调用当前线程的线程组的ThreadGroup.enumerate（Thread []）方法。应用程序可能使用activeCount方法来估计数组应该有多大，但是如果数组太短而无法容纳所有线程，则会以静默方式忽略额外的线程。 如果获取当前线程的线程组及其子组中的每个活动线程至关重要，则调用者应验证返回的int值是否严格小于tarray的长度。 由于此方法存在固有的竞争条件，因此建议该方法仅用于调试和监视目的。 123public static int enumerate(Thread tarray[]) &#123; return currentThread().getThreadGroup().enumerate(tarray);&#125; 使用示例12345678910111213141516171819202122232425262728293031323334353637/** * @author Aaryn * @date 2019/7/16 19:02 */public class CreateThreadGroup &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; try &#123; // t1线程的逻辑执行时间 TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; t1.start(); TimeUnit.SECONDS.sleep(1); System.out.println("t1线程的名称为:" + t1.getName()); // t1线程的执行时间必须多于主线程的sleep时间，t1的线程组才为main // 因为获取线程组信息时线程的状态必须是活跃的，否则会返回null System.out.println("t1线程的线程组信息为:" + t1.getThreadGroup()); ThreadGroup threadGroup = Thread.currentThread().getThreadGroup(); Thread[] threads = new Thread[threadGroup.activeCount()]; // 该方法只会将活动线程复制到指定的线程数组中，所以如果在调用该方法时 // t1线程已经处于“死亡”状态，那么在输出的线程数组中将看不到t1线程 threadGroup.enumerate(threads); Arrays.stream(threads).forEach(System.out::println); &#125;&#125; 执行逻辑单元start()作用使该线程开始执行; Java虚拟机调用此线程的run 方法。 结果是两个线程同时运行：当前线程从调用返回到start 方法和另一个线程执行运行逻辑。 注意点多次启动线程或者结束后再次启动线程都会抛出异常IllegalThreadStateException。 源码分析123456789101112131415161718192021public synchronized void start() &#123; // 0标识线程的NEW状态 if (threadStatus != 0) throw new IllegalThreadStateException(); // 通知线程组该线程即将启动，以便可以将其添加到组的线程列表中，并且可以递减组的未启动计数 group.add(this); boolean started = false; try &#123; // 调用本地方法 start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; // 本地方法抛出异常时直接调用堆栈 &#125; &#125;&#125; run()当构造线程时传入了Runnable接口的实现，就会执行该实现中的run()方法，否则不会产生任何操作 12345public void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; 调用run()方法与start()方法区别直接调用线程的run方法一样可以执行指定的逻辑单元，但是这样做是没有意义的，因为我们创建线程的目的是为了能够实现并发操作，而直接调用run方法是主线程去工作，其实程序还是在串行化操作。 另外一点就是调用start()方法执行逻辑单元只能被调用一次，当线程执行结束后如果再次尝试启动线程会抛出异常；而run方法没有调用限制。 个人理解就是业务执行逻辑是不确定的，所以应该通过继承Thread类或者实现Runnable接口来将业务逻辑放在run()方法中；而start()方法中会包含固定的线程管理相关的逻辑，比如权限校验，线程状态校验，线程组等 1234567891011121314151617181920212223242526272829/** * @author Aaryn * @date 2019/7/15 23:22 * &lt;p&gt; * 模拟简单的模板方法体验Thread类start()方法与run()方法的巧妙 */public class Template &#123; public final void print(String message) &#123; System.out.println("***********"); wrapPrint(message); System.out.println("***********"); &#125; protected void wrapPrint(String message) &#123; &#125; public static void main(String[] args) &#123; Template t1 = new Template() &#123; @Override protected void wrapPrint(String message) &#123; System.out.println("##" + message + "##"); &#125; &#125;; t1.print("hello template"); &#125;&#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JDK源码解读</tag>
        <tag>Thread</tag>
        <tag>线程基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM之类的加载连接初始化以及类的主动使用]]></title>
    <url>%2F2019%2F03%2F11%2FJava%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2FJVM%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E4%B9%8B%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E8%BF%9E%E6%8E%A5%E5%88%9D%E5%A7%8B%E5%8C%96%E4%BB%A5%E5%8F%8A%E7%B1%BB%E7%9A%84%E4%B8%BB%E5%8A%A8%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概述在Java代码中，类型的加载、连接与初始化[过程都是在程序运行期间完成的，提供了更大的灵活性，增加了更多的可能性与灵活性 加载：最常见的形式就是将已经存在的class文件从磁盘上加载到内存中 连接：将类与类之间的调用关系确定好（比如将类与类之间的符号引用转化为直接引用），并且完成对字节码的验证、校验等（字节码文件可能被人为修改） 初始化：对静态变量的赋值等工作 灵活性：类的加载、连接与初始化并不一定严格按照顺序进行，具体根据JVM规范的要求，如果JVM只是做了描述，那么根据厂商的不同可能具体的实现也会各不相同。 Java虚拟机与程序的生命周期如下几种情况Java虚拟机将结束生命周期 程序中执行了 System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 个人理解虚拟机结束生命周期可以分为两种情况：第一种是我们期望的程序生命周期结束，比如主动在程序中调用exit()方法或者程序正常结束；第二种就是我们不可预见的程序结束生命周期，比如程序抛出无法捕获的异常或者操作系统层面发生错误引起的程序结束。 类的加载概述将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在内存中创建一个java.lang.Class对象，用于封装类在方法区内的数据结构 加载.class文件的方式 从本地系统直接加载 通过网络下载.class文件 从zip,jar等归档文件中加载.class文件 从专有数据库中提取.class文件 将Java源文件动态编译为.class文件 动态代理 类的连接概述类被Java虚拟机加载后，就进入连接阶段。连接阶段Java虚拟机会将已经读入到内存中的类的二进制数据合并到虚拟机的运行时环境中去。 验证确保被加载类的正确性（保证字节码文件符合JVM的规范与要求） 验证内容 类文件的结构检查 语义检查 字节码验证 二进制兼容性验证 准备分配内存为类的静态变量分配内存，并将其设置为默认值 在准备阶段其实虚拟机中还没有创建类的对象实例，所以涉及不到给对象实例分配内存 解析解析过程就是在类型的常量池中寻找类、接口、字段和方法的符号引用，把这些符号引用替换成直接引用的过程 类的初始化作用 为类的静态变量赋予程序指定的初始值 静态变量初始化的两种途径 在静态变量的声明处进行初始化 1public static final String STR = UUID.randomUUID().toString(); 在静态代码块中进行初始化 123static &#123; final String STR2 = UUID.randomUUID().toString();&#125; 初始化时机Java虚拟机初始化一个类时要求它的所有父类都已经被初始化，但是这条规则不适用于接口。 只有当程序访问的静态变量或者静态方法确实在当前类或者当前接口中定义时，才可以认为是对类或者接口的主动使用。 类的初始化步骤 假如类还没有被加载和连接，那么先进行加载和连接 假如类存在直接父类，并且这个父类还没有被初始化，那么就先初始化直接父类 假如类中存在初始化语句，那就依次执行这些初始化语句（按照声明顺序自上而下初始化） 接口初始化 在初始化一个类时，并不会先初始化它所实现的接口 在初始化一个接口时，并不会先初始化它的父接口 只有当程序首次使用特定接口的静态变量时，才会导致该接口的初始化。 对于接口中的变量默认就是被public static final进行修饰的，在方法中调用接口中的常量时，如果该常量是编译期可以确定的值，那么是不会引起对接口的初始化的；如果该常量是运行期才能够确定的值，那么会对该接口进行初始化，但是不会初始化该接口的父接口。 静态代码块与实例代码块静态代码块是在类初始化阶段被执行的，代码块中的方法只会被执行一次；而实例代码块是在每次创建对象的时候执行的，执行时机是在每次构造方法被调用前先去执行实例代码块。 123456789101112// 静态代码块class c&#123; static&#123; System.out.println("c static block."); &#125;&#125;// 实例代码块class c&#123; &#123; System.out.println("invoke c"); &#125;&#125; 注意点静态变量引用对于静态字段来说，只有直接定义了该字段的类才会被初始化。 虽然只有直接定义字段的类才会被初始化，但是并不意味着虚拟机不会执行类的加载与连接工作。 对于下面的示例代码，虽然使用子类去调用父类中的静态变量，但是表示的是对父类的主动使用，那么就只会导致对父类进行初始化而不会初始化子类。 123456789101112131415161718192021222324252627282930public class MyTest &#123; public static String STR = "hello world in MyTest"; public static void main(String[] args) &#123; System.out.println(MyChild.str); &#125;&#125;class MyParent &#123; public static String str = "hello world"; static &#123; System.out.println("this is MyParent static block"); &#125;&#125;class MyChild extends MyParent&#123; public static String str1 = "myChild hello world"; static &#123; System.out.println("this is MyChild static block"); &#125;&#125;// 执行结果[Loaded com.geekerit.jvmlearn.classloader.MyTest from file:/E:/IDEA_FILE/1/JVMInAction/target/classes/]......// 两个类都已经被加载到虚拟机中[Loaded com.geekerit.jvmlearn.classloader.MyParent from file:/E:/IDEA_FILE/1/JVMInAction/target/classes/][Loaded com.geekerit.jvmlearn.classloader.MyChild from file:/E:/IDEA_FILE/1/JVMInAction/target/classes/]// 从打印结果看出虽然通过MyChild调用父类的静态变量，但是并没有打印MyChild中静态代码块的语句，说明MyChild类并没有进行初始化this is MyParent static blockhello world[Loaded java.lang.Shutdown from E:\JAVA\jdk8\jre\lib\rt.jar][Loaded java.lang.Shutdown$Lock from E:\JAVA\jdk8\jre\lib\rt.jar] 当一个类在初始化时，要求其父类已经全部初始化完毕123456789101112131415161718192021222324252627282930public class MyTest &#123; public static String STR = "hello world in MyTest"; public static void main(String[] args) &#123; System.out.println(MyChild.str); &#125;&#125;class MyParent &#123; public static String str = "hello world"; static &#123; System.out.println("this is MyParent static block"); &#125;&#125;class MyChild extends MyParent&#123; public static String str = "myChild hello world"; static &#123; System.out.println("this is MyChild static block"); &#125;&#125;// 从程序的执行结果可以看出来虽然我们只是调用了子类的静态变量，但是还是会先去初始化其父类，然后再对子类进行初始化[Loaded com.geekerit.jvmlearn.classloader.MyTest from file:/E:/IDEA_FILE/jvm_learn/target/classes/]......[Loaded com.geekerit.jvmlearn.classloader.MyParent from file:/E:/IDEA_FILE/jvm_learn/target/classes/][Loaded com.geekerit.jvmlearn.classloader.MyChild from file:/E:/IDEA_FILE/jvm_learn/target/classes/]this is MyParent static blockthis is MyChild static blockmyChild hello world[Loaded java.lang.Shutdown from E:\JAVA\jdk8\jre\lib\rt.jar][Loaded java.lang.Shutdown$Lock from E:\JAVA\jdk8\jre\lib\rt.jar] 调用常量的初始化编译期常量 常量在编译阶段如果值是可以确定的，那么该常量会存入到调用这个常量的方法所在的类的常量池中，本质上，调用类并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 12345678910111213141516171819public class MyTest &#123; // 这里由于是main方法调用的MyParent类中的常量，那么程序在编译阶段就会将该常量放入到main方法所在的类也就是MyTest类的常量池中，那么在程序运行时实际上引用的是MyTest类中的常量，与MyPatent类已经没有任何关系，那么MyParent类自然不会被触发初始化 public static void main(String[] args) &#123; System.out.println(MyParent.STR); &#125;&#125;class MyParent &#123; public static final String STR = "hello world"; static &#123; System.out.println("this is MyParent static block"); &#125;&#125;/* 执行结果以及类加载关键信息 */// 加载main方法所在的启动类[Loaded com.geekerit.jvm_learn.classloader.MyTest from file:/E:/IDEA_FILE/jvm_learn/target/classes/]......// 只打印出了常量信息，并没有执行MyParent类的静态代码块，说明MyParent类并没有被初始化hello world 运行期常量 当一个常量的值是在运行期才可以确定的，那么其常量就不会被放到调用类的常量池中，只有在程序运行时使用到该常量时，会导致对这个常量所在的类的主动使用，从而导致这个类被初始化。 12345678910111213141516public class MyTest2 &#123; public static void main(String[] args) &#123; // STR只有在运行时才能确定具体的值，所以该方法会导致MyParent3类的初始化 System.out.println(MyParent3.STR); &#125;&#125;class MyParent3&#123; // 运行时常量 public static final String STR = UUID.randomUUID().toString(); static &#123; System.out.println("MyParent3 static block"); &#125;&#125;/* 程序执行结果 */MyParent3 static blocka89726ae-920e-4c57-9f6c-d1da8414d834 数组初始化对于数组实例来说，其类型是由JVM在运行期动态生成的，例如下边代码中表示为class [Lcom.geekerit.jvmlearn.classloader.MyParent4;，动态生成的类型其父类型为Object. 对于数组来说，Javadoc经常将构成数组的元素称为component，实际上就是将数组降低一个维度之后的类型。 1234567891011121314151617181920212223242526public class MyTest4 &#123; public static void main(String[] args) &#123; MyParent4[] myParent4s = new MyParent4[1]; System.out.println(myParent4s.getClass()); System.out.println(myParent4s.getClass().getSuperclass()); System.out.println("------------"); int[] ints = new int[1]; System.out.println(ints.getClass()); boolean[] booleans = new boolean[1]; System.out.println(booleans.getClass()); &#125;&#125;class MyParent4&#123; static &#123; System.out.println("MyParent4 static block"); &#125;&#125;/* 执行结果 */class [Lcom.geekerit.jvm_learn.classloader.MyParent4; class java.lang.Object------------class [Iclass [Z 接口初始化当一个接口在初始化时，并不要求其父接口都完成了初始化，只有在真正使用到父接口的时候（如引用接口中所定义的常量时），才会初始化 由于接口中不允许定义静态代码块，所以我们在接口内定义一个线程，当我们使用接口中的线程时，如果对接口进行了初始化，那么线程中的实例代码块就会被执行。 12345678910111213141516171819202122232425262728293031323334public class MyTest5 &#123; public static void main(String[] args) &#123; // 调用子接口中的静态变量时父接口中的实例代码块并没有被执行，意味着调用子接口中的静态变量并没有导致对父接口的初始化 System.out.println(MyIter2.THREAD); &#125;&#125;interface MyIter1 &#123; public static Thread THREAD = new Thread() &#123; &#123; System.out.println("MyIter1 invoke..."); &#125; @Override public String toString() &#123; return "MyIter1 。。。"; &#125; &#125;;&#125;interface MyIter2 extends MyIter1 &#123; public static Thread THREAD = new Thread() &#123; &#123; System.out.println("MyIter2 invoke..."); &#125; @Override public String toString() &#123; return "MyIter2 。。。"; &#125; &#125;;&#125;// 执行结果MyIter2 invoke...MyIter2 。。。 当一个类被初始化的时候，它所实现的接口是不会被初始化的 123456789101112131415161718public class MyTest5 &#123; // 程序的输出结果为6，并不会输出接口中实例代码块的内容 public static void main(String[] args) &#123; System.out.println(MyChild5.b); &#125;&#125;interface MyPatent5 &#123; public static Thread THREAD = new Thread() &#123; &#123; System.out.println("MyParent5 invoke..."); &#125; &#125;;&#125;class MyChild5 implements MyPatent5 &#123; public static int b = 6;&#125; 静态变量赋值类加载器在准备阶段会给静态变量赋予其系统内置的初始值，而在初始化阶段才会赋给静态变量程序中显示指定的初始值 1234567891011121314151617181920212223242526272829public class MyTest6 &#123; public static void main(String[] args) &#123; // 调用类的静态方法获取类的实例 MyParent6 myParent6 = MyParent6.getInstance(); System.out.println("counta:" + MyParent6.counta); System.out.println("countb:" + MyParent6.countb); &#125;&#125;class MyParent6&#123; // ②类初始化时由于程序并没有对变量counta显示赋值，counta会被设置为默认值0,而countb会被设置为显示指定的初始值0 public static int counta; public static int countb = 0; // ③ 执行该语句时会调用该类的无参构造创建类的实例 private static MyParent6 myParent6 = new MyParent6(); // ④ 创建类实例 private MyParent6()&#123; // 对类中的静态变量的值进行操作，此时counta=0;countb=0; counta++; // counta==1; countb++; // countb==1; &#125; //① 获取实例时会调用该类的静态方法，在调用时就会触发对该类的初始化，初始化时类会从上到下执行 public static MyParent6 getInstance()&#123; return myParent6; &#125;&#125;// 执行结果counta:1countb:1 调整静态变量countb的位置 1234567891011121314151617181920212223242526272829303132public class MyTest6 &#123; public static void main(String[] args) &#123; // 调用类的静态方法获取类的实例 MyParent6 myParent6 = MyParent6.getInstance(); System.out.println("counta:" + MyParent6.counta); System.out.println("countb:" + MyParent6.countb); &#125;&#125;class MyParent6&#123; // ② 没有显示指定counta的值，将保持counta类加载准备阶段的默认值0 public static int counta; // ③ 调用该类的无参构造创建类的实例 private static MyParent6 myParent6 = new MyParent6(); // ④ 创建实例 private MyParent6()&#123; // 此时counta已经完成初始化，counta=0; counta++; // counta==1; // 此时countb尚未完成初始化，使用类加载准备阶段时的值，countb=0; countb++; // countb==1; &#125; // ⑤ 将countb的值初始化为指定值0 public static int countb = 0; // countb==0; //① 获取实例时会调用该类的静态方法，在调用时就会触发对该类的初始化，初始化时类会从上到下执行 public static MyParent6 getInstance()&#123; return myParent6; &#125;&#125;// 执行结果counta:1countb:0 反射调用ClassLoader类的loadClass()方法加载一个类，并不是对类的主动使用，不会导致对类的初始化；而通过反射去获取类的class对象属于对类的主动使用，会导致对类的初始化 123456789101112131415161718192021222324public class MyTest10 &#123; public static void main(String[] args) throws ClassNotFoundException &#123; // 获取系统类加载器 ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); String className = "com.geekerit.jvmlearn.classloader.Load"; Class&lt;?&gt; aClass = systemClassLoader.loadClass(className); System.out.println(aClass); System.out.println("---------"); // 反射获取Class对象 aClass = Class.forName(className); System.out.println(aClass); &#125;&#125;class Load &#123; static &#123; System.out.println("Load static block..."); &#125;&#125;// 程序执行结果class com.geekerit.jvmlearn.classloader.Load---------Load static block...class com.geekerit.jvmlearn.classloader.Load 个人理解虚拟机想要去创建一个类，第一步必然应该先找到该类的二进制数据即类的.class文件，这就是类的加载；而虚拟机为了保证类能够被安全加载，在连接阶段的第一步需要先对查找到的数据进行验证，只有验证通过后才会进入准备阶段去给类变量（静态变量）分配内存并根据其类型初始化为默认值，在准备阶段的最后一步会将类中的符号引用转换为直接引用；在类的初始化阶段会将程序指定的值赋给类变量。 类的使用Java程序对类的使用方式分为两种：主动使用与被动使用。所有的Java虚拟机实现必须在每个类或接口被Java程序“首次主动使用”时再进行初始化。 类主动使用的情况创建类的实例12345678910111213public class ClassUseCase &#123; public static void main(String[] args) &#123; MyClassCreate m1 = new MyClassCreate(); &#125;&#125;class MyClassCreate被初始化&#123; static &#123; System.out.println("MyClassCreate static block.."); &#125;&#125;// 控制台输出结果，静态代码块被执行，说明MyClassCreate被初始化MyClassCreate static block.. 访问某个类或接口的静态变量，或者对该静态变量赋值123456789101112131415161718192021222324public class ClassUseCase &#123; public static void main(String[] args) &#123; System.out.println(MyClassStaticFieldGet.STR); MyClassStaticFieldSet.STR = "Set Value"; &#125;&#125;class MyClassStaticFieldGet&#123; public static String STR = "Hello World"; static &#123; System.out.println("MyClassStaticField static block.."); &#125;&#125;class MyClassStaticFieldSet&#123; public static String STR = "Hello World"; static &#123; System.out.println("MyClassStaticFieldSet static block.."); &#125;&#125;// 控制台输出结果MyClassStaticFieldGet static block..Hello WorldMyClassStaticFieldSet static block.. 调用类的静态方法1234567891011121314151617public class ClassUseCase &#123; public static void main(String[] args) &#123; MyClassStaticMethod.print(); &#125;&#125;class MyClassStaticMethod&#123; public static void print()&#123; System.out.println("MyClassStaticMethod"); &#125; static &#123; System.out.println("MyClassStaticMethod static block.."); &#125;&#125;// 执行结果MyClassStaticMethod static block..MyClassStaticMethod 反射123456789101112public class ClassUseCase &#123; public static void main(String[] args) throws ClassNotFoundException &#123; Class.forName("com.geekerit.jvmlearn.classloader.MyClassReflect"); &#125;&#125; class MyClassReflect&#123; static &#123; System.out.println("MyClassReflect static block.."); &#125;&#125;// 执行结果MyClassReflect static block.. 初始化一个类的子类1234567891011121314public class ClassUseCase &#123; public static void main(String[] args) throws ClassNotFoundException &#123; MyClassChild classChild = new MyClassChild(); &#125;&#125;class MyClassParent&#123; static &#123; System.out.println("MyClassParent static block.."); &#125;&#125;class MyClassChild extends MyClassParent&#123;&#125;// 执行结果MyClassParent static block.. Java虚拟机启动时被标明为启动类的类123456789public class ClassUseCase &#123; static &#123; System.out.println("ClassUseCase static block.."); &#125; public static void main(String[] args) throws ClassNotFoundException &#123; &#125;&#125;// 执行结果ClassUseCase static block.. JDK7开始提供动态语言支持java.lang.invoke.MethodHandle实例的解析结果REF_getStatic,REF_putStatic,REF_invokeStatic句柄对应的类没有初始化时，则初始化 类的卸载类被卸载后将不能再创建该类的对象，除非重新将该类的字节码文件加载到JVM中。 当类被加载连接和初始化之后，它的生命周期就开始了。当代表类的Class对象不再被引用时，Class对象就会结束生命周期，类在方法区内的数据也会被卸载，从而结束类的生命周期。 一个类何时结束生命周期取决于代表他的Class对象何时结束生命周期。 由Java虚拟机自带的类加载器（根类加载器、扩展类加载器以及系统类加载器）加载的类，在虚拟机的生命周期中始终不会被卸载。Java虚拟机本身会始终引用这些类加载器，而这些类加载器又会始终引用他们所加载的类的Class对象，因此这些Class对象始终是可触及的。 由用户自定义的类加载器加载的类是可以被卸载的。 相关知识Java自带的查询虚拟机使用情况的工具jconsole jvisualvm jmap命令行工具 助记符12// 反编译Java的`.class`文件javap -c test.class 123456ldc 表示将int，float或者String类型的常量值从常量池中推送至栈顶bipush 表示将单字节（-128-127）的常量值推送至栈顶sipush 表示将一个短整型的常量值（-32768-32767）推送至栈顶iconst_1 表示将数值1推送至栈顶（iconst_m1 ~ iconst_5标识将常量-1-5推送至栈顶）anewarray 表示创建一个引用类型（如类，接口，数组等）的数组，并将其引用值压入栈顶newarray 表示创建一个指定的原始类型（如int,float,char等）的数组，并将其引用值压入栈顶 JVM相关参数1234567-XX:+TraceClassLoading:用于追踪类的加载信息并进行打印-XX:+TraceClassUnloading:用于追踪类的卸载信息并进行打印// 设置jvm参数的三种形式-XX:+&lt;option&gt;:表示开启option选项-XX:-&lt;option&gt;:表示关闭option选项-XX:&lt;option&gt;=&lt;value&gt;:表示将option选项的值设置为value// 使用jvisualvm.exe查看类的装载与卸载信息]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>类加载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化]]></title>
    <url>%2F2019%2F03%2F03%2Fnosql%2Fredis%2F%E6%8C%81%E4%B9%85%E5%8C%96%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[为什么需要进行持久化操作Redis是纯内存操作，而内存中的内容在发生操作系统宕机或者进程突然退出等情况时会发生丢失，所以需要对Redis服务器中的内容进行持久化操作，将内存中的数据持久化到磁盘中，这样在下次Redis服务启动之前可以利用持久化的文件进行数据恢复，尽可能保证生产数据的完整性。 什么情况下需要开启Redis持久化如果只是使用Redis缓存简单的非重要的业务数据，个人认为完全没有必要开启Redis的持久化功能 ，因为只有Redis中的业务数据缺失重要时开启持久化才是有意义的。 持久化方式概述Redis 支持 RDB和 AOF 两种持久化机制。 RDB什么是RDBRDB持久化是把当前进程数据生成快照保存到硬盘的过程，触发 RDB持久化过程分为手动触发和自动触发。 RDB工作流程待补充流程图 1）执行 bgsave 命令，Redis 父进程判断当前是否存在正在执行的子进程，如 RDB/AOF 子进程，如果存在 bgsave 命令直接返回。 2）父进程执行 fork 操作创建子进程，fork 操作过程中父进程会阻塞，通过 info stats 命令查看 latest_fork_usec 选项，可以获取最近一个 fork 操作的耗时，单位为微秒。 3）父进程 fork 完成后，bgsave 命令返回“Background saving started”信息并不再阻塞父进程，可以继续响应其他命令。 4）子进程创建 RDB 文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换。执行 lastsave 命令可以获取最后一次生成 RDB 的时间，对应 info 统计的 rdb_last_save_time 选项。 5）进程发送信号给父进程表示完成，父进程更新统计信息，具体见 info Persistence 下的 rdb_* 相关选项。 在指定时间间隔内将内存中的数据集快照到磁盘中，恢复时将快照文件直接读取到内存中 redis会单独fork一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程全部结束后再用这个临时文件替换上次持久化的文件。整个过程中不进行任何的IO操作，确保了极高的性能。 RDB持久化的优点适合全量备份RDB是一个紧凑压缩的二进制文件，代表 Redis 在某个时间点上的数据快照。非常适用于备份，全量复制等场景。 数据恢复速度快如果需要进行大规模的数据恢复，并且对数据恢复的完整性不是特别敏感，那么RDB的方式要比AOF更加高效。 使用RDB进行持久化存在哪些问题系统开销大bgsave 每次运行都要执行 fork 操作创建子进程，属于重量级操作，频繁执行成本过高。 可能丢失部分数据RDB按照指定的时间间隔进行数据备份，那么在最后一次时间间隔内发生系统故障时，最后一次还未持久化数据可能会被丢失 内存占用高在fork进程的时候内存中的数据会被克隆，大致2倍的内存膨胀需要考虑 文件格式兼容问题RDB文件使用特定格式的二进制文件存储，Redis多个版本之间的RDB文件可能存在不兼容情况 RDB相关配置解读保存文件为dump.rdb 生产环境下会将备份好的RDB文件通过自动化脚本传输到备用机器上，防止出现单机故障造成数据完全丢失 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 触发RDB的默认配置# 在15min内至少1个key发生修改save 900 1# 在5min内至少10个key发生修改220 save 300 10# 在60秒内至少10000个key发生修改221 save 60 10000---# 在客户端写操作发生错误时是否停止RDB后台备份stop-writes-on-bgsave-error yes# 对于存储到磁盘中的快照设置是否进行压缩存储rdbcompression yes# 对备份数据进行校验rdbchecksum yes---# 触发备份行为# 全部阻塞后进行保存（阻塞当前 Redis 服务器，直到 RDB 过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。）save# 后台异步进行快照保存，快照同时还可以响应客户端的请求（Redis 进程执行 fork 操作创建子进程，RDB 持久化过程由子进程负责，完成后自动结束。阻塞只发生在 fork 阶段，一般时间很短。）bgsave# flushall也会触发备份行为，但是生成的RDB文件内容为空---# 恢复备份文件# 可以将备份文件移动到redis的安装目录启动服务即可# 获取RDB文件位置CONFIG GET dir# 设置RDB文件的保存路径config set dir dirName# 设置RDB文件的文件名config set dbfilename newFileName# 是否开启RDB文件压缩config set rdbcompression &#123;yes|no&#125;---# 禁用RDB# 如果需要禁用可以在配置文件中使用如下进行配置 save "" # 也可以通过客户端进行配置redis-cli config set save ""---# RDB文件发生损坏时检测工具# Redis加载已损坏RDB文件会无法启动# Short read or OOM loading DB. Unrecoverable error, aborting now.redis-check-dump # ？？使用方式 AOF（append only file）什么是AOF以独立日志的方式记录每次写命令，重启时再重新执行 AOF 文件中的命令达到恢复数据的目的。AOF 的主要作用是解决了数据持久化的实时性，目前已经是 Redis 持久化的主流方式。 1234567891011121314151617# 开启AOF（默认不开启）appendonly yes# `AOF`文件命名appendfilename "appendonly.aof"# `AOF`持久化设置appendfsync everysec# 重写时是否可以运用appendfsyncno-appendfsync-on-rewrite no# 设置`AOF`重写的基准值# 代表当前 AOF 文件空间（aof_current_size）和上一次重写后 AOF 文件空间（aof_base_size）的比值。auto-`AOF`-rewrite-percentage 100# 表示运行 AOF 重写时文件最小体积auto-`AOF`-rewrite-min-size 64mb# 修复`AOF`文件redis-check-aof --fix appendonly.aof AOF工作流程图片 1）所有的写入命令会追加到 aof_buf（缓冲区）中。 Redis 使用单线程响应命令，如果每次写 AOF 文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载。 先写入缓冲区 aof_buf 中，还有另一个好处，Redis 可以提供多种缓冲区同步硬盘的策略，在性能和安全性方面做出平衡。 2）AOF 缓冲区根据对应的策略向硬盘做同步操作。 3）随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。 4）当 Redis 服务器重启时，可以加载 AOF 文件进行数据恢复。 AOF文件与RDB文件同时存在时，Redis启动时会优先读取AOF文件进行数据恢复，因为通常情况下AOF文件保存的数据集会比RDB文件保存的数据集更完整，但是如果AOF存在错误会导致Redis服务无法启动 劣势 相同数据集AOF文件远大于RDB文件恢复速度同样慢于RDB AOF的运行效率慢于RDB，每秒同步策略效率较高 使用AOF恢复数据步骤 配置文件打开AOF配置 将AOF文件复制备份到对应目录中 重启Redis服务进行数据加载 如果AOF文件被写坏使用命令进行修复后重启服务进行加载 AOF文件重写机制AOF重写刷盘策略 策略 说明 always 同步持久化，每次发生数据变更会被立即记录至磁盘中，性能较差但是数据完整性好 everysec 默认配置，异步操作，每秒记录一次，可能会数据丢失 no 从不同步 什么是AOF文件重写机制AOF采用文件追加方式，文件会越来越大，重写机制可以保证AOF文件的大小超过所设定的阈值时，Redis对AOF文件的内容进行压缩，只保留可以恢复数据的最小指令集，可以使用命令bgrewriteAOF触发机制 Redis会记录上次重写时AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍并且文件大于64M时触发 AOF文件重写后为什么可以变小写命令中的数据已经被删除旧的AOF文件中可能存在无效的写命令，比如在数据写入之后又发生了数据的删除命令，那么该命令其实已经失效了 写命令中的数据已经过期进程内可能存在超时的数据，在旧的AOF文件中可能存在含有过期时间的写入命令，数据过期后该命令已经失效 多条写命令的合并针对相同键的部分写命令可以进行合并 AOF重写的优点降低了AOF文件占用磁盘的空间 加快了AOF文件被加载的速度 Redis持久化文件加载流程1）AOF 持久化开启且存在 AOF 文件时，优先加载 AOF 文件 2）AOF 关闭或者 AOF 文件不存在时，加载 RDB 文件， 3）加载 AOF/RDB 文件成功后，Redis 启动成功。 4）AOF/RDB 文件存在错误时，Redis 启动失败并打印错误信息。 RDB与AOF的性能调优建议RDB文件只用作数据库数据备份，建议只在Slave上持久化RDB文件，而且配置15分钟备份规则就可以满足需要 如果开启AOF，好处是最恶劣情况下不会丢失超过两秒的数据，代价是带来了持续的IO操作，并且AOF rewrite最后将产生的新数据写到新文件造成的阻塞几乎不可避免。在硬盘许可的情况下应该尽量减少rewrite的频率，AOF重写的基础大小默认值64M可以设置为5GB以上，默认超过原大小的100%可以改为适当的数值。 如果不开启AOF，仅靠主从复制实现高可用也是可以的，减去频繁的IO操作与rewrite带来的系统波动，代价是主从如果同时挂掉会丢失数据，启动脚本需要比较主从中的RDB文件，载入较新的RDB文件恢复数据。 参考资料 书籍：《Redis开发与运维》]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>缓存</tag>
        <tag>持久化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-MVC接收参数]]></title>
    <url>%2F2019%2F02%2F26%2Fframework%2FSpring%20MVC%2FSpring%20MVC%E6%8E%A5%E6%94%B6%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[接收方式不用注解直接接受参数 需要注意的是controller中的形参需要与HTTP请求的参数名称保持一致 URL 1http://127.0.0.1:8081/param/no/annotation?userId=1&amp;username=arwin&amp;age=24 控制器 12345678910111213@RequestMapping(value = "/no/annotation") @ResponseBody public Map noAnnotation(Long userId, String username, Integer age) &#123; return getMap(userId, username, age); &#125; private Map getMap(Long userId, String username, Integer age) &#123; Map&lt;String, Object&gt; paramsMap = new HashMap&lt;&gt;(16); paramsMap.put("id", userId); paramsMap.put("username", username); paramsMap.put("age", age); return paramsMap; &#125; 使用 @RequestParam 注解接收参数 URL 1http://127.0.0.1:8081/param/request/param?user_id=1&amp;user_name=arwin 控制器 123456789101112131415private Map getMap(Long userId, String username, Integer age) &#123; Map&lt;String, Object&gt; paramsMap = new HashMap&lt;&gt;(16); paramsMap.put("id", userId); paramsMap.put("username", username); paramsMap.put("age", age); return paramsMap; &#125; @RequestMapping(value = "/request/param") @ResponseBody public Map requestParam(@RequestParam(value = "user_id") Long userId, @RequestParam(value = "user_name") String username, @RequestParam(value = "user_age", required = false, defaultValue = "18") Integer age) &#123; return getMap(userId, username, age); &#125; 使用 @RequestBody 接收 JSON 参数 URL 1http://127.0.0.1:8081/param/request/body 控制器 123456@PostMapping("/request/body")@ResponseBodypublic User requestBody(@RequestBody User user) &#123; System.out.println(user.toString()); return user;&#125; 通过 @PathVariable 接收参数 URL 1http://127.0.0.1:8081/param/url/1 控制器 12345@GetMapping(value = "/url/&#123;userId&#125;") @ResponseBody public Map getByUrl(@PathVariable("userId") Long userId)&#123; return getMap(userId,"url",20); &#125; 接收数组类型参数 URL 1http://127.0.0.1:8081/param/request/array?intArr=1,2,3&amp;longArr=1,2,3&amp;strArr=arwin,aaryn 控制器 12345678910@GetMapping("/request/array") @ResponseBody public Map&lt;String, Object&gt; requestArray( int [] intArr, Long []longArr, String[] strArr) &#123; Map&lt;String, Object&gt; paramsMap = new HashMap&lt;&gt;(16); paramsMap.put("intArr", intArr); paramsMap.put("longArr", longArr); paramsMap.put("strArr", strArr); return paramsMap; &#125; 自定义参数转换规则设置自定义的参数转换器（规则:{id}-{userName}-{note}）123456789101112131415@Componentpublic class UserConverter implements Converter&lt;String, User&gt; &#123; @Override public User convert(String userStr) &#123; User user = new User(); String []strArr = userStr.split("-"); Long id = Long.parseLong(strArr[0]); String userName = strArr[1]; String note = strArr[2]; user.setUserId(id); user.setUserName(userName); user.setNote(note); return user; &#125;&#125; 定义控制器进行测试12345@GetMapping(&quot;/converter&quot;) @ResponseBody public User getUserByConverter(User user) &#123; return user; &#125; 访问接口查看1http://127.0.0.1:8081/param/converter?user=1-username1-note_1]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis键空间通知]]></title>
    <url>%2F2019%2F02%2F26%2Fnosql%2Fredis%2F%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2FRedis%E9%94%AE%E9%80%9A%E7%9F%A5%2F</url>
    <content type="text"><![CDATA[分类中文文档键通知事件介绍 个人理解 键空间通知：事件的订阅者可以拿到的信息是某一个键被执行事件的名称，是针对某一个键发生的改动进行的事件监控； 键事件通知：事件的订阅者可以拿到的信息是发生该事件的键名称，是针对某一事件进行的主体监控，例如监控过期键，监控被删除键等； 配置默认情况下该通知行为是关闭的，原因可能有： 开启键空间通知功能需要消耗一些 CPU 该功能对于大多数的使用者可能并没有意义 配置方式 redis 配置文件 redis.conf 中设置键通知 12# Ex为示例，实际根据自己需要参照参数介绍进行配置notify-keyspace-events Ex 登录 redis 服务端后执行命令进行配置 12# Ex为示例，实际根据自己需要参照参数介绍进行配置config set notify-keyspace-events Ex 参数介绍 字符 通知类型 K 键空间通知，所有通知以 __keyspace@&lt;db&gt;__ 为前缀 E 键事件通知，所有通知以 __keyevent@&lt;db&gt;__ 为前缀 g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知 $ 字符串命令的通知 l 列表命令的通知 s 集合命令的通知 h 哈希命令的通知 z 有序集合命令的通知 x 过期事件：每当有过期键被删除时发送 e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送 A 参数 g$lshzxe 的别名 Springboot 使用项目配置 redis 连接信息123456789101112131415spring: redis: port: 6379 password: ****** host: 127.0.0.1 timeout: 1000 jedis: pool: max-active: 10 min-idle: 5 max-idle: 10 max-wait: 2000 cache: type: redis cache-names: redisCache 启动类中创建任务池，等待处理 redis 消息12345678910111213141516// 任务池 private ThreadPoolTaskScheduler taskScheduler = null; /** * 创建任务池，运行线程等待处理Redis的消息 * @return 任务池 */ @Bean public ThreadPoolTaskScheduler initTaskScheduler() &#123; if (taskScheduler != null) &#123; return taskScheduler; &#125; taskScheduler = new ThreadPoolTaskScheduler(); taskScheduler.setPoolSize(20); return taskScheduler; &#125; 定义 redis 的监听容器123456789101112131415161718192021222324252627282930/** * 定义Redis的监听容器 * @return 监听容器 */ @Bean public RedisMessageListenerContainer initRedisContainer() &#123; RedisMessageListenerContainer container = new RedisMessageListenerContainer(); // Redis连接工厂 container.setConnectionFactory(connectionFactory); // 设置运行任务池 container.setTaskExecutor(initTaskScheduler()); // 定义监听渠道，名称为topic1 Topic topicTest = new ChannelTopic("topic1"); // 针对键过期事件定义监听渠道 Topic topicEvent = new ChannelTopic("__keyevent@0__:expired"); // 针对具体的键定义监听渠道 Topic topicSpace = new ChannelTopic("__keyspace@0__:key1"); // 针对正则匹配的键定义监听渠道 Topic topicSpaceOfPattern = new PatternTopic("__keyspace@0__:key*"); // 创建需要redis监听的渠道集合 Collection&lt;Topic&gt; topicCollection = new ArrayList&lt;&gt;(); topicCollection.add(topicTest); topicCollection.add(topicEvent); topicCollection.add(topicSpace); topicCollection.add(topicSpaceOfPattern); // 使用监听器监听Redis的消息 container.addMessageListener(redisMsgListener,topicCollection); return container; &#125; 创建 redis 消息监听器 RedisMessageListener12345678910111213@Componentpublic class RedisMessageListener implements MessageListener &#123; @Override public void onMessage(Message message, byte[] pattern) &#123; // 消息体 String body = new String(message.getBody()); // 渠道名称 String topic = new String(pattern); System.out.println(body); System.out.println(topic); &#125;&#125; 项目案例案例介绍业务场景为会员定制化服务，会员自己设定周期订购服务，要求在订购期前提醒用户进行确认收货地址，并且在收到商品后的七天之内将不满意的商品进行退回。 案例分析时间节点为任务，可以使用redis键空间通知完成，在每个节点生成监控键，并且需要注意键的设计，因为redis的键空间通知在键过期后只能得到过期的键名称，无法获取过期键的内容。 案例实现源码地址 关键点案例是利用redis的键空间通知的键过期事件通知，获取到过期键的内容进行业务处理，所以redis键的设计至关重要，在业务复杂的情况下可以使用 统一前缀+业务类型+业务主体信息作为键，方便进行业务区分。 另外redis的键过期事件并不是在过期时间到达后立即发生，而是在redis过期键在被驱逐后才会发生，这决定于redis的过期键驱逐策略，所以过期时间不一定会特别精准，如果对时间有高精准要求的业务请慎重使用此解决方案。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot集成JSP]]></title>
    <url>%2F2019%2F02%2F20%2Fframework%2Fspringboot%2FSpring%20Boot%E9%9B%86%E6%88%90JSP%E6%AD%A5%E9%AA%A4%2F</url>
    <content type="text"><![CDATA[maven项目添加相关依赖1234567891011&lt;!-- tomcat支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- jstl标签库 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; 在main目录下新建webapp/WEB-INF目录 Module Settings中设置web选项 项目配置文件中设置jsp文件的访问路径123456789server: port: 8082spring: mvc: view: # 页面默认前缀目录 prefix: /WEB-INF/jsp/ # 响应页面默认后缀 suffix: .jsp 新建jsp文件 controller中设置访问路径12345678@Controllerpublic class controller &#123; @RequestMapping(value = "/index",method = RequestMethod.GET) public String index()&#123; return "index"; &#125;&#125; 通过maven插件启动项目并测试访问]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Java</tag>
        <tag>JSP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis基础数据结构之SortedSet有序集合]]></title>
    <url>%2F2019%2F01%2F24%2Fnosql%2Fredis%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2FSortedSet%2F</url>
    <content type="text"><![CDATA[ZADD语法1ZADD key score member [[score member] [score member] ...] 参数说明 key 要添加的有序集合的键名称 score 要添加的有序集合成员的分数 member 要添加到有序集合中的成员 [score member] 表示可以同时添加多个成员与对应分支的键值对 作用将一个或多个 member 元素及其 score 值加入到有序集 key 当中。如果某个 member 已经是有序集的成员，那么更新这个 member 的 score 值，并通过重新插入这个 member 元素，来保证该 member 在正确的位置上。score 值可以是整数值或双精度浮点数。如果 key 不存在，则创建一个空的有序集并执行 ZADD 操作。当 key 存在但不是有序集类型时，返回一个错误。 时间复杂度O(M*log(N))， N 是有序集的基数， M 为成功添加的新成员的数量。 返回值被成功添加的新成员的数量，不包括那些被更新的、已经存在的成员。 示例图片 ZCARD语法1ZCARD key 参数说明 key 有序集合的键名称作用返回有序集 key 的基数。时间复杂度O(1)返回值当 key 存在且是有序集类型时，返回有序集的基数。当 key 不存在时，返回 0 。示例图片 ZCOUNT语法1ZCOUNT key min max 参数说明 key 有序集合的键名称 min 有序集合中score的最小取值 max 有序集合中score的最大取值作用返回有序集 key 中， score 值在 min 和 max 之间(默认包括 score 值等于 min 或 max )的成员的数量。时间复杂度O(log(N))， N 为有序集的基数。返回值score 值在 min 和 max 之间的成员的数量。示例图片 ZINCRBY语法1ZINCRBY key increment member 参数说明 key 有序集合的键名称 increment 对有序集合成员的score值要操作的增量 member 要操作的有序集合的成员作用为有序集 key 的成员 member 的 score 值加上增量 increment 。可以通过传递一个负数值 increment ，让 score 减去相应的值，比如 ZINCRBY key -5 member ，就是让 member 的 score 值减去 5 。当 key 不存在，或 member 不是 key 的成员时， ZINCRBY key increment member 等同于 ZADD key increment member 。当 key 不是有序集类型时，返回一个错误。score 值可以是整数值或双精度浮点数。时间复杂度O(log(N))返回值member 成员的新 score 值，以字符串形式表示。示例图片 ZRANGE语法1ZRANGE key start stop [WITHSCORES] 参数说明 key 有序集合的键名称 start 有序集合成员下标的起始值，0表示第一个成员 stop 有序集合成员下标的结束值，-1表示最后一个成员 [WITHSCORES] 可选项，表示查询有序集合成员时是否同时返回成员的score值作用返回有序集 key 中，指定区间内的成员。其中成员的位置按 score 值递增(从小到大)来排序。具有相同 score 值的成员按字典序(lexicographical order )来排列。如果你需要成员按 score 值递减(从大到小)来排列，请使用 ZREVRANGE 命令。下标参数 start 和 stop 都以 0 为底，也就是说，以 0 表示有序集第一个成员，以 1 表示有序集第二个成员，以此类推。你也可以使用负数下标，以 -1 表示最后一个成员， -2 表示倒数第二个成员，以此类推。超出范围的下标并不会引起错误。比如说，当 start 的值比有序集的最大下标还要大，或是 start &gt; stop 时， ZRANGE 命令只是简单地返回一个空列表。另一方面，假如 stop 参数的值比有序集的最大下标还要大，那么 Redis 将 stop 当作最大下标来处理。可以通过使用 WITHSCORES 选项，来让成员和它的 score 值一并返回，返回列表以 value1,score1, ..., valueN,scoreN 的格式表示。客户端库可能会返回一些更复杂的数据类型，比如数组、元组等。时间复杂度O(log(N)+M)， N 为有序集的基数，而 M 为结果集的基数。返回值指定区间内，带有 score 值(可选)的有序集成员的列表。示例图片 ZRANGEBYSCORE语法1ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] 参数说明 key 有序集合的键名称 min 有序集合成员score的最小取值 max 有序集合成员score的最大取值 [WITHSCORES] 查询结果是否同时返回符合条件成员的score值 [LIMIT offset count] 对查询的结果集进行数量限制，offset表示结果集的起始位置，count表示取出结果集的几个结果，例如结果集是[1,2,3]，limit 0 2，则最终结果是[1,2]作用返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。具有相同 score 值的成员按字典序(lexicographical order)来排列(该属性是有序集提供的，不需要额外的计算)。可选的 LIMIT 参数指定返回结果的数量及区间(就像SQL中的 SELECT LIMIT offset, count )，注意当 offset 很大时，定位 offset 的操作可能需要遍历整个有序集，此过程最坏复杂度为 O(N) 时间。可选的 WITHSCORES 参数决定结果集是单单返回有序集的成员，还是将有序集成员及其 score 值一起返回。该选项自 Redis 2.0 版本起可用。区间min 和 max 可以是 -inf 和 +inf ，这样一来，你就可以在不知道有序集的最低和最高 score 值的情况下，使用 ZRANGEBYSCORE 这类命令。默认情况下，区间的取值使用闭区间 (小于等于或大于等于)，你也可以通过给参数前增加 ( 符号来使用可选的开区间 (小于或大于)。时间复杂度O(log(N)+M)， N 为有序集的基数， M 为被结果集的基数。返回值指定区间内，带有 score 值(可选)的有序集成员的列表。示例图片 ZRANK语法1ZRANK key member 参数说明 key 有序集合的键名称 member 要查询的有序集合中的成员作用返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递增(从小到大)顺序排列。排名以 0 为底，也就是说， score 值最小的成员排名为 0 。使用 ZREVRANK 命令可以获得成员按 score 值递减(从大到小)排列的排名。时间复杂度O(log(N))返回值如果 member 是有序集 key 的成员，返回 member 的排名。如果 member 不是有序集 key 的成员，返回 nil 。示例图片 ZREM语法1ZREM key member [member ...] 参数说明 key 有序集合的键名称 member 要删除的有序集合的成员 [member …] 可以同时删除多个成员作用移除有序集 key 中的一个或多个成员，不存在的成员将被忽略。当 key 存在但不是有序集类型时，返回一个错误。时间复杂度O(M*log(N))， N 为有序集的基数， M 为被成功移除的成员的数量。返回值被成功移除的成员的数量，不包括被忽略的成员。示例图片 ZREMRANGEBYRANK语法1ZREMRANGEBYRANK key start stop 参数说明 key 有序集合的键名称 start 有序集合成员的下标起始值 stop 有序集合成员的下标结束值作用移除有序集 key 中，指定排名(rank)区间内的所有成员。区间分别以下标参数 start 和 stop 指出，包含 start 和 stop 在内。下标参数 start 和 stop 都以 0 为底，也就是说，以 0 表示有序集第一个成员，以 1 表示有序集第二个成员，以此类推。你也可以使用负数下标，以 -1 表示最后一个成员， -2 表示倒数第二个成员，以此类推。时间复杂度O(log(N)+M)， N 为有序集的基数，而 M 为被移除成员的数量。返回值被移除成员的数量。示例图片 ZREMRANGEBYSCORE语法1ZREMRANGEBYSCORE key min max 参数说明 key 有序集合的键名称 min 有序集合score的最小取值 max 有序集合score的最大取值作用移除有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。自版本2.1.6开始， score 值等于 min 或 max 的成员也可以不包括在内，详情请参见 ZRANGEBYSCORE 命令。时间复杂度O(log(N)+M)， N 为有序集的基数，而 M 为被移除成员的数量。返回值被移除成员的数量。示例图片 ZREMRANGEBYLEX语法1ZREMRANGEBYLEX key min max 参数说明 key 有序集合的键名称 min 有序集合中成员下标的起始值 max 有序集合中成员下标的结束值 作用对于一个所有成员的分值都相同的有序集合键 key 来说， 这个命令会移除该集合中， 成员介于 min 和 max 范围内的所有元素。时间复杂度O(log(N)+M)， 其中 N 为有序集合的元素数量， 而 M 则为被移除的元素数量。返回值整数回复：被移除的元素数量。示例图片 ZREVRANGE语法1ZREVRANGE key start stop [WITHSCORES] 参数说明 key 有序集合的键名称 start 有序集合成员下标起始值 stop 有序集合成员下标结束值 [WITHSCORES] 是否返回结果集中的成员对应score值作用返回有序集 key 中，指定区间内的成员。其中成员的位置按 score 值递减(从大到小)来排列。具有相同 score 值的成员按字典序的逆序(reverse lexicographical order)排列。除了成员按 score 值递减的次序排列这一点外， ZREVRANGE 命令的其他方面和 ZRANGE 命令一样。时间复杂度O(log(N)+M)， N 为有序集的基数，而 M 为结果集的基数。返回值指定区间内，带有 score 值(可选)的有序集成员的列表。示例图片 ZREVRANGEBYSCORE语法1ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] 参数说明 key 有序集合的键名称 max 有序集合中score的最小取值 min 有序集合中score的最大取值 [WITHSCORES] 结果集中是否返回有序集合成员对应的score值 [LIMIT offset count] 是否对返回的结果集进行数量限制作用返回有序集 key 中， score 值介于 max 和 min 之间(默认包括等于 max 或 min )的所有的成员。有序集成员按 score 值递减(从大到小)的次序排列。具有相同 score 值的成员按字典序的逆序(reverse lexicographical order )排列。除了成员按 score 值递减的次序排列这一点外， ZREVRANGEBYSCORE 命令的其他方面和 ZRANGEBYSCORE 命令一样。时间复杂度O(log(N)+M)， N 为有序集的基数， M 为结果集的基数。返回值指定区间内，带有 score 值(可选)的有序集成员的列表。示例图片 ZREVRANK语法1ZREVRANK key member 参数说明 key 有序集合的键名称 member 有序集合中要查询的成员作用返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递减(从大到小)排序。排名以 0 为底，也就是说， score 值最大的成员排名为 0 。使用 ZRANK 命令可以获得成员按 score 值递增(从小到大)排列的排名。时间复杂度O(log(N))返回值如果 member 是有序集 key 的成员，返回 member 的排名。如果 member 不是有序集 key 的成员，返回 nil 。示例图片 ZSCORE语法1ZSCORE key member 参数说明 key 有序集合的键名称 member 要查询的有序集合中的成员作用返回有序集 key 中，成员 member 的 score 值。如果 member 元素不是有序集 key 的成员，或 key 不存在，返回 nil 。时间复杂度O(1)返回值member 成员的 score 值，以字符串形式表示。示例图片 ZUNIONSTORE语法1ZUNIONSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX] 参数说明 destination 结果集保存的目标集合 numkeys 操作集合的数量 key 要操作的有序集合的键名称 [key …] 多个有序集合的键名称 [WEIGHTS weight [weight …]] 是否在聚合之前将有序集合的成员score值乘对应的乘法因子，默认为1 [AGGREGATE SUM|MIN|MAX] 结果并集的聚合方式作用计算给定的一个或多个有序集的并集，其中给定 key 的数量必须以 numkeys 参数指定，并将该并集(结果集)储存到 destination 。默认情况下，结果集中某个成员的 score 值是所有给定集下该成员 score 值之 _和_ 。WEIGHTS使用 WEIGHTS 选项，你可以为 _每个_分别_ 指定一个乘法因子(multiplication factor)，每个给定有序集的所有成员的 score 值在传递给聚合函数(aggregation function)之前都要先乘以该有序集的因子。如果没有指定 WEIGHTS 选项，乘法因子默认设置为 1 。AGGREGATE使用 AGGREGATE 选项，你可以指定并集的结果集的聚合方式。默认使用的参数 SUM ，可以将所有集合中某个成员的 score 值之 _和_ 作为结果集中该成员的 score 值；使用参数 MIN ，可以将所有集合中某个成员的 _最小_ score 值作为结果集中该成员的 score 值；而参数 MAX 则是将所有集合中某个成员的 _最大_ score 值作为结果集中该成员的 score 值。时间复杂度O(N)+O(M log(M))， N 为给定有序集基数的总和， M 为结果集的基数。返回值保存到 destination 的结果集的基数。示例图片 查询成员成绩之和 查询成员的优秀成绩 查询成员的较差成绩 使用乘法因子完成员工的年终奖的计算 计算出员工在每个项目拿到的年终奖的较大值与较小值 ZINTERSTORE语法1ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX] 参数说明与ZUNIONSTORE参数意义一致 作用计算给定的一个或多个有序集的交集，其中给定 key 的数量必须以 numkeys 参数指定，并将该交集(结果集)储存到 destination 。默认情况下，结果集中某个成员的 score 值是所有给定集下该成员 score 值之和. 时间复杂度O(NK)+O(Mlog(M))， N 为给定 key 中基数最小的有序集， K 为给定有序集的数量， M 为结果集的基数。 返回值保存到 destination 的结果集的基数。 示例图片 ZRANGEBYLEX语法1ZRANGEBYLEX key min max [LIMIT offset count] 参数说明 key 有序集合的键名称 min 有序集合成员下标的起始值 max 有序集合成员下标的结束值 [LIMIT offset count] 结果集限制作用当有序集合的所有成员都具有相同的分值时， 有序集合的元素会根据成员的字典序（lexicographical ordering）来进行排序， 而这个命令则可以返回给定的有序集合键 key 中， 值介于 min 和 max 之间的成员。如果有序集合里面的成员带有不同的分值， 那么命令返回的结果是未指定的（unspecified）。命令会使用 C 语言的 memcmp() 函数， 对集合中的每个成员进行逐个字节的对比（byte-by-byte compare）， 并按照从低到高的顺序， 返回排序后的集合成员。 如果两个字符串有一部分内容是相同的话， 那么命令会认为较长的字符串比较短的字符串要大。可选的 LIMIT offset count 参数用于获取指定范围内的匹配元素 （就像 SQL 中的 SELECT LIMIT offset count 语句）。 需要注意的一点是， 如果 offset 参数的值非常大的话， 那么命令在返回结果之前， 需要先遍历至 offset 所指定的位置， 这个操作会为命令加上最多 O(N) 复杂度。指定范围区间合法的 min 和 max 参数必须包含 ( 或者 [ ， 其中 ( 表示开区间（指定的值不会被包含在范围之内）， 而 [ 则表示闭区间（指定的值会被包含在范围之内）。特殊值 + 和 - 在 min 参数以及 max 参数中具有特殊的意义， 其中 + 表示正无限， 而 - 表示负无限。 因此， 向一个所有成员的分值都相同的有序集合发送命令 ZRANGEBYLEX &lt;zset&gt; - + ， 命令将返回有序集合中的所有元素。时间复杂度O(log(N)+M)， 其中 N 为有序集合的元素数量， 而 M 则是命令返回的元素数量。 如果 M 是一个常数（比如说，用户总是使用 LIMIT 参数来返回最先的 10 个元素）， 那么命令的复杂度也可以看作是 O(log(N)) 。返回值数组回复：一个列表，列表里面包含了有序集合在指定范围内的成员。示例图片 ZLEXCOUNT语法1ZLEXCOUNT key min max 参数说明 key 有序集合的键名称 min 有序集合的成员下标起始值 max 有序集合的成员下标结束值作用对于一个所有成员的分值都相同的有序集合键 key 来说， 这个命令会返回该集合中， 成员介于 min 和 max 范围内的元素数量。时间复杂度O(log(N))，其中 N 为有序集合包含的元素数量。返回值整数回复：指定范围内的元素数量。示例图片 实战案列案列说明学校进行期末考试完成后部分科目成绩公布如下 姓名 英语 数学 Alice 89 97 brown 91 68 curry 76 99 danny 98 97 jhon 89 97 klay 79 68 要求： 将学生的科目成绩分别存储在不同的有序集合中； 成绩校验后发现curry的英文成绩少计算了13分，在学生的英文成绩记录中进行更正； 计算英语成绩在90分以上的同学数量； 列出数学成绩低于80分的同学，并要求知道他们的具体分数； 将英语成绩按照从低到高的排序方式进行排列，然后将数学成绩按照从高到底的排序方式排列； 计算所有学生的英语与数学成绩的总和，并且需要根据成绩进行排名； 查询klay的数学成绩 danny英文考试作弊，移出本次的成绩清单，并重新计算学生总成绩与排名； 查询Alice的总成绩的班级排名 解题 使用ZADD进行有序集合新增 使用 zincrby 进行键的score值的变更 使用 zcount 进行有序集合根据score值筛选并统计member数量 使用 zrangebyscore 进行成绩筛选 zrevrange将有序集合按照score倒序排列 使用zunionscore求出学生的成绩总和 使用zscore查询member的score值 zrem删除有序集合中的member zrank查询元素在有序集合中的排名]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis基础学习（二）Set集合]]></title>
    <url>%2F2019%2F01%2F23%2Fnosql%2Fredis%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F2019-01-23-redis%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[SADD语法1SADD key member [member ...] 参数说明 key 集合的键名称 member 要添加到集合中的成员 [member …] 可以同时添加多个作用将一个或多个 member 元素加入到集合 key 当中，已经存在于集合的 member 元素将被忽略。假如 key 不存在，则创建一个只包含 member 元素作成员的集合。当 key 不是集合类型时，返回一个错误。时间复杂度O(N)， N 是被添加的元素的数量。 返回值被添加到集合中的新元素的数量，不包括被忽略的元素。 示例图片 SCARD语法1SCARD key 参数说明 key 集合的键名称作用返回集合 key 的基数(集合中元素的数量)。时间复杂度O(1)返回值集合的基数。当 key 不存在时，返回 0 。示例图片 SDIFF语法1SDIFF key [key ...] 参数说明 key 要进行比较的第一个集合 [key …] 剩余需要与第一个集合进行比较的集合作用返回由第一个集和所有连续集之间的差异产生的集合的成员。时间复杂度O(N)， N 是所有给定集合的成员数量之和。返回值一个包含差集成员的列表。示例图片 SDIFFSTORE语法1SDIFFSTORE destination key [key ...] 参数说明 destination 结果集要存储的集合名称 key 要比较的第一个集合 [key …] 要比较的剩余连续集合作用这个命令的作用和 SDIFF 类似，但它将结果保存到 destination 集合，而不是简单地返回结果集。如果 destination 集合已经存在，则将其覆盖。destination 可以是 key 本身。时间复杂度O(N)， N 是所有给定集合的成员数量之和。返回值结果集中的元素数量。示例图片 SINTER语法1SINTER key [key ...] 参数说明 key 第一个要操作的集合 [key …] 剩余的连续集合作用返回一个集合的全部成员，该集合是所有给定集合的交集。不存在的 key 被视为空集。当给定集合当中有一个空集时，结果也为空集(根据集合运算定律)。时间复杂度O(N * M)， N 为给定集合当中基数最小的集合， M 为给定集合的个数。返回值交集成员的列表。示例图片 SINTERSTORE语法1SINTERSTORE destination key [key ...] 参数说明 destination 结果集保存的集合名称 key 操作的第一个集合 [key …] 剩余的连续集合作用这个命令类似于 SINTER 命令，但它将结果保存到 destination 集合，而不是简单地返回结果集。如果 destination 集合已经存在，则将其覆盖。destination 可以是 key 本身。时间复杂度O(N * M)， N 为给定集合当中基数最小的集合， M 为给定集合的个数。返回值结果集中的成员数量。示例图片 SISMEMBER语法1SISMEMBER key member 参数说明 key 集合的键名称 member 要查询的成员作用判断 member 元素是否集合 key 的成员。时间复杂度O(1)返回值如果 member 元素是集合的成员，返回 1 。如果 member 元素不是集合的成员，或 key 不存在，返回 0 。示例图片 SMEMBERS语法1SMEMBERS key 参数说明 key 集合的键名称作用返回集合 key 中的所有成员。不存在的 key 被视为空集合。时间复杂度O(N)， N 为集合的基数。返回值集合中的所有成员。示例图片 SMOVE语法1SMOVE source destination member 参数说明 source 元素所在的集合 destination 元素要移动到的目标集合 member 要移动的集合元素作用将 member 元素从 source 集合移动到 destination 集合。SMOVE 是原子性操作。如果 source 集合不存在或不包含指定的 member 元素，则 SMOVE 命令不执行任何操作，仅返回 0 。否则， member 元素从 source 集合中被移除，并添加到 destination 集合中去。当 destination 集合已经包含 member 元素时， SMOVE 命令只是简单地将 source 集合中的 member 元素删除。当 source 或 destination 不是集合类型时，返回一个错误。时间复杂度O(1)返回值如果 member 元素被成功移除，返回 1 。如果 member 元素不是 source 集合的成员，并且没有任何操作对 destination 集合执行，那么返回 0 。示例图片 SPOP语法1SPOP key 参数说明 key 操作的集合的键名称作用移除并返回集合中的一个随机元素。如果只想获取一个随机元素，但不想该元素从集合中被移除的话，可以使用 SRANDMEMBER 命令。时间复杂度O(1)返回值被移除的随机元素。当 key 不存在或 key 是空集时，返回 nil 。示例图片 SRANDMEMBER语法1SRANDMEMBER key [count] 参数说明 key 集合的键名称 [count] 要返回的键数量作用如果命令执行时，只提供了 key 参数，那么返回集合中的一个随机元素。从 Redis 2.6 版本开始， SRANDMEMBER 命令接受可选的 count 参数： 如果 count 为正数，且小于集合基数，那么命令返回一个包含 count 个元素的数组，数组中的元素各不相同。如果 count 大于等于集合基数，那么返回整个集合。 如果 count 为负数，那么命令返回一个数组，数组中的元素可能会重复出现多次，而数组的长度为 count 的绝对值。 该操作和 SPOP 相似，但 SPOP 将随机元素从集合中移除并返回，而 SRANDMEMBER 则仅仅返回随机元素，而不对集合进行任何改动。 时间复杂度只提供 key 参数时为 O(1) 。如果提供了 count 参数，那么为 O(N) ，N 为返回数组的元素个数。 返回值只提供 key 参数时，返回一个元素；如果集合为空，返回 nil 。如果提供了 count 参数，那么返回一个数组；如果集合为空，返回空数组。 示例图片 SREM语法1SREM key member [member ...] 参数说明 key 集合的键名称 member 要删除的集合成员 [member …] 可同时删除多个作用移除集合 key 中的一个或多个 member 元素，不存在的 member 元素会被忽略。当 key 不是集合类型，返回一个错误。时间复杂度O(N)， N 为给定 member 元素的数量。返回值被成功移除的元素的数量，不包括被忽略的元素。示例图片 SUNION语法1SUNION key [key ...] 参数说明 key 要操作的第一个集合 [key …] 剩余的连续集合作用返回一个集合的全部成员，该集合是所有给定集合的并集。不存在的 key 被视为空集。时间复杂度O(N)， N 是所有给定集合的成员数量之和。返回值并集成员的列表。示例图片 SUNIONSTORE语法1SUNIONSTORE destination key [key ...] 参数说明 destination 结果集保存的目标集合 key 要操作的第一个集合 [key …] 剩余的连续集合作用这个命令类似于 SUNION 命令，但它将结果保存到 destination 集合，而不是简单地返回结果集。如果 destination 已经存在，则将其覆盖。destination 可以是 key 本身。时间复杂度O(N)， N 是所有给定集合的成员数量之和。返回值结果集中的元素数量。示例图片 参考文章 redis命令参考 redis commands]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis基础学习（一）]]></title>
    <url>%2F2019%2F01%2F06%2Fnosql%2Fredis%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F2019-01-06-redis%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[简介安装简介redis是一种使用内存作为存储介质的NoSQL型数据库 常用场景 缓存常用不常变数据，减少与数据库的交互，提高数据的访问速度 关系型数据库（mysql等支持的并发访问量较少，而redis支持的并发访问量则成倍增加） 分布式锁（setnx,incr） pub/sub模式 安装centos7安装配置redis4 数据结构Stringset操作语法1SET key value [EX seconds] [PX milliseconds] [NX|XX] 作用​ 将value值关联到key上 注意事项 如果key已经关联有其他value，则SET操作会覆盖原有值； 如果key原来存在过期时间，当SET操作执行后过期时间将被清除； 常用操作 设置键值的同时设置键过期时间 1234# 时间单位为秒SET key value EX second# 时间单位为毫秒SET key value PX millisecond 新增键值(键不存在时才会设置) 1SET key value NX 覆盖键值(键存在时才会设置) 1SET key value XX 获取字符串长度语法1STRLEN key 作用​ 返回 key 所储存的字符串值的长度。key不存在时返回长度为0 注意事项​ 当 key 储存的不是字符串值时，返回一个错误。 字符串追加语法1APPEND key value 作用​ 如果 key 已经存在并且是一个字符串， APPEND 命令将 value 追加到 key 原来的值的末尾。 ​ 如果 key 不存在， APPEND 就简单地将给定 key 设为 value ，就像执行 SET key value 一样。 字符串覆盖语法1SETRANGE key offset value 作用 用 value 参数覆写(overwrite)给定 key 所储存的字符串值，从偏移量 offset 开始。 不存在的 key 当作空白字符串处理。 SETRANGE 命令会确保字符串足够长以便将 value 设置在指定的偏移量上，如果给定 key 原来储存的字符串长度比偏移量小(比如字符串只有 5 个字符长，但你设置的 offset 是 10 )，那么原字符和偏移量之间的空白将用零字节(zerobytes, &quot;\x00&quot; )来填充。 注意事项 你能使用的最大偏移量是 2^29-1(536870911) ，因为 Redis 字符串的大小被限制在 512 兆(megabytes)以内。如果你需要使用比这更大的空间，你可以使用多个 key 。 获取字符串子串语法1GETRANGE key start end 作用 返回 key 中字符串值的子字符串，字符串的截取范围由 start 和 end 两个偏移量决定(包括 start 和 end 在内)。 负数偏移量表示从字符串最后开始计数， -1 表示最后一个字符， -2 表示倒数第二个，以此类推。 GETRANGE 通过保证子字符串的值域(range)不超过实际字符串的值域来处理超出范围的值域请求。 注意事项​ 该操作只支持正向获取子串，不支持回绕操作。例如，你可以获取从0-4下标的子串，但是不能获取从4-2下标的子串。 数值增减 命令 语法 作用 注意事项 INCR INCR key 将 key 中储存的数字值增一。 如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 INCR 操作。如果值包含错误的类型，或字符串类型的值不能表示为数字，那么返回一个错误。本操作的值限制在 64 位(bit)有符号数字表示之内。 INCRBY INCRBY key increment 将 key 所储存的值加上增量 increment 。 同上 INCRBYFLOAT INCRBYFLOAT key increment 为 key 中所储存的值加上浮点数增量 increment 。 DECR DECR key 将 key 中储存的数字值减一。 同上 DECRBY DECRBY key decrement 将 key 所储存的值减去减量 decrement 。 同上 String实战 get，set命令：常用于数据缓存，与关系型数据库结合使用，存储数据时同时存储在redis与关系型数据库，取值时首先从redis中进行获取，减少与数据库的交互，提高数据的访问速度。 setnx:常用于分布式锁，数据不存在时才新增 incr:秒杀场景 setbit:签到功能，权限分配等 ​]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot集成七牛云搭建自己的免费图床]]></title>
    <url>%2F2018%2F12%2F15%2Fframework%2Fspringboot%2F2018-12-15-%E5%9F%BA%E4%BA%8E%E4%B8%83%E7%89%9B%E4%BA%91%E4%BD%BF%E7%94%A8Spring%20Boot%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%B7%B1%E7%9A%84%E5%85%8D%E8%B4%B9%E5%9B%BE%E5%BA%8A%2F</url>
    <content type="text"><![CDATA[大家在写markdown的时候时常会用到上传图片的问题，本人使用的是七牛云做图片存储，每月的免费存储流量足够个人笔记使用，下边简单总结下我使用springboot基于七牛云搭建自己的免费图床的步骤，只需要修改关键参数即可体验。 项目地址体验流程1.开通自己的七牛云的账号并进行域名配置等操作，具体操作参照七牛云文档2.下载项目到本地修改配置后启动项目查看效果 需修改参数 包路径 参数介绍 AK constants 七牛云AK SK constants 是否 BUCKET constants 空间名称 IMAGE_URL_HTTP_VALUE constants 个人配置的空间域名 IMAGE_URL_HTTP_VALUE_SUFFIX constants 七牛云开启原图保护的间隔符与后缀，非必须 logback.xml 项目根路径下 修改为自己的本地文件夹的路径即可，否则项目启动可能会报错 3.启动项目并访问地址进行上传访问路径：localhost:8888 上传成功后即可获取图片地址，直接复制图片路径访问]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Springboot</tag>
        <tag>七牛云</tag>
        <tag>图床</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot集成阿里云短信服务]]></title>
    <url>%2F2018%2F12%2F13%2Fframework%2Fspringboot%2F2018-12-13-Spring%20Boot%E9%9B%86%E6%88%90%E9%98%BF%E9%87%8C%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Some are born great, some achieve greatness, and some have greatness thrust upon them. 有些人天生不凡，有些人后来获得卓越，还有些人被迫伟大。 开发环境： 工具：idea2018.3 Springboot版本：2.1.1 JDK版本：1.8 构建工具：Maven API展示：Swagger2 简介​ 互联网项目离不开短信服务，无论是日常的登录验证码或者用户相关的操作以及营销活动，都需要为用户发送短信，本项目为最初始版本的springboot集成阿里云短信服务的demo，只需要下载到本地修改响应开发参数后即可运行，项目的局限性以及优化之后会总结并更新。 使用指引1.阿里云短信服务使用指引2.根据指引开通服务后开始编写服务代码3.添加maven依赖1234567891011121314151617181920&lt;!--阿里云短信通知依赖--&gt; &lt;!-- https://mvnrepository.com/artifact/com.aliyun/aliyun-java-sdk-core --&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;3.7.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-dysmsapi&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--阿里云短信依赖json--&gt; &lt;!-- https://mvnrepository.com/artifact/org.json/json --&gt; &lt;dependency&gt; &lt;groupId&gt;org.json&lt;/groupId&gt; &lt;artifactId&gt;json&lt;/artifactId&gt; &lt;version&gt;20180130&lt;/version&gt; &lt;/dependency&gt; 4.项目目录结构介绍 5.运行需修改参数 参数 所在目录 介绍 password application-dev/application-online redis连接密码 ACCESSSKEY_ID constants/SmsConstants 阿里云短信服务开发者信息AK ACCESSKEY_SECRET constants/SmsConstants 阿里云短信服务开发者信息SK SIGN_NAME constants/SmsConstants 短信签名 TEMPLATE_YZ_LOGIN constants/SmsConstants 短信模板 注意事项： ​ 1.运行项目前确认本地9999端口未被占用，否则请修改配置文件的server.port属性； ​ 2.线上项目的SwaggerConfig中的@Profile(value = “dev”)value值设置为自己的线上环境配置文件名称； 6.运行项目输入swagger地址查看接口测试地址：localhost:8888/swagger-ui.html 如果线上环境切换成IP地址即可，生产环境记得禁用swagger。 说明： ​ 1.项目只是为了让用户体会阿里云的短信服务的功能，需要用户开通阿里云短信服务的功能后才能进行使用； ​ 2.项目中的短信模板以及短信签名都放在常量类中，项目小的情况下还能进行维护，如果短信服务做独立服务的话应该把这些变量作为参数传递或者使用配置中心进行解耦。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Springboot</tag>
        <tag>短信服务</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows中使用vmware搭建虚拟机并使用远程连接工具进行统一管理]]></title>
    <url>%2F2018%2F11%2F20%2FLinux%2F2018-11-20-%E4%BD%BF%E7%94%A8vmware%E5%AE%89%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%B9%B6%E4%BD%BF%E7%94%A8%E8%BF%9C%E7%A8%8B%E5%B7%A5%E5%85%B7%E8%BF%9B%E8%A1%8C%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[首先需要安装虚拟机软件vmware：官网链接 虚拟机的网络设置：查看自己的宿主机的网络配置，打开CMD输入ipconfig查看 在vmware中进行网络设置点击编辑—虚拟网络编辑器； 点击更改设置，设置子网IP的网段与宿主机的网段一致；如果宿主机IP为192.168.0.1，则子网IP设置为192.168.0.XXX即可；子网掩码保持默认即可(这样做的目的是为了之后使用远程连接工具管理虚拟机，如果直接使用vmware进行虚拟机的相关操作可以不用与宿主机的IP段保持一致)；注意使用本地的DHCP服务要取消勾选： 点击NET设置，设置自己的网关IP进行记录，之后虚拟机中设置网络时需要； 开始安装虚拟机：创建虚拟机： 选择稍后安装系统； 选择要安装的linux的版本； 选择要安装的位置并 定义虚拟机名称，一般我以IP进行命名方便进行集群操作，另外虚拟机的安装目录最好统一放在同一目录下； 磁盘大小一般选择默认即可； 选择要安装的操作系统； 跳过系统检测开始进行系统安装； 设置系统的时区以及要支持的语言； 设置系统网络; 选择IPV4 Settings--method，选择Manual,Address输入要设置的虚拟机IP，只要与上述自己设置的网关的IP段保持一致即可，Netmask为上述的子网掩码，Gateway为上述自己设置的网关地址，输入完成点击save进行保存： 设置root用户的登录密码； 添加普通用户并设置登录密码，可略过； 等待系统安装完成进行重启； 登录系统查看网络信息1ifconfig ![(C:\Users\15927\Pictures\学习\开发环境\虚拟机\17编辑网络.png) 修改网络信息配置文件，设置静态IP12vi vi /etc/sysconfig/network-scripts/ifcfg-ens33上述的文件名称根据自己的网卡名称编写 个人配置信息参考： 123456789101112131415161718192021TYPE=&quot;Ethernet&quot;PROXY_METHOD=&quot;none&quot;BROWSER_ONLY=&quot;no&quot;BOOTPROTO=&quot;static&quot;DEFROUTE=&quot;yes&quot;IPV4_FAILURE_FATAL=&quot;no&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;IPV6_DEFROUTE=&quot;yes&quot;IPV6_FAILURE_FATAL=&quot;no&quot;IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot;NAME=&quot;ens33&quot;UUID=&quot;cf0e2c3c-8afe-47a3-96d0-59cc57ad1b14&quot;DEVICE=&quot;ens33&quot;ONBOOT=&quot;yes&quot;IPADDR=&quot;192.168.0.5&quot;PREFIX=&quot;24&quot;GATEWAY=&quot;192.168.0.100&quot;DNS1=8.8.8.8DNS2=&quot;192.168.0.100&quot;IPV6_PRIVACY=&quot;no&quot;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>虚拟机</tag>
        <tag>运维</tag>
        <tag>Vmware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper客户端操作及ACL权限控制]]></title>
    <url>%2F2018%2F11%2F11%2Fmicroservice%2Fdubbo%2Fzookeeper%2F2018-11-11-zookeeper%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C%E4%BB%A5%E5%8F%8AACL%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[zookeeper客户端操作及ACL权限控制简介作用： 中间件 ，提供协调服务 作用于分布式系统，为大数据服务 支持java 什么是分布式系统： 多台计算机组成整体，一致对外处理同一请求 内部计算机相互通信 客户端到服务端一次请求到响应结束历经多台计算机 分布式系统瓶颈 一致性：数据一致性，数据分批入库 原子性：不会局部化 单一视图：数据一致 可靠性：每次对ZK操作都保存在服务端 实时性：客户端读取ZK服务端最新数据 zookeeper基本数据模型 树形结构，可理解为Linux文件目录 每个节点称为znode, 每个节点分为临时节点与永久节点 每个zk节点都有各自的版本号，节点数据发生变化版本号会累加 删除/修改过时节点 zk节点存储的数据不宜过大 节点可以设置权限ACL zookeeper作用 master节点选举，主节点挂了以后从节点接手并保证唯一（首脑模式），保证集群高可用 配置文件统一管理，提高运维效率 发布与订阅，类似消息队列 提供分布式锁，分布式环境不同进程之间竞争资源 集群管理，集群中保证数据的强一致性 常用客户端命令操作客户端登录 语法格式 1./zkCli.sh ls与ls2命令 语法格式 12ls path [watch]ls2 path [watch] ls命令查看某节点下的节点数 ls2命令查看某节点的详细信息，等同于ls+stat get与stat 语法格式 12get path [watch]stat path [watch] get 获取节点数据 stat 获取当前节点状态，详细参数如下： 节点项 含义 cZxid zookeeper为节点分配的ID ctime 节点创建时间 mZxid 修改后的节点ID mtime 修改时间 pZxid 子节点ID cversion 子节点版本 dataVersion 数据版本号 aclVersion 权限版本号 ephemeralOwner 临时节点数量 dataLength 数据长度 numChildren 子节点数量 create创建节点 -s为顺序节点 -e为临时节点 create命令语法 1create [-s] [-e] path data acl create path data 默认创建非顺序持久化节点 create -s path data 创建顺序节点 create -e path data 创建临时节点 set 更改节点数据 语法格式 1set path data [version] set path data 直接修改节点数据 set path data [version] 基本版本号修改节点数据（乐观锁) delete 删除节点数据 语法格式 1delete path [version] delete path 直接删除节点 delete path [version] 基于版本号删除节点（乐观锁 ) session基本原理 客户端与服务端之间的连接存在会话 每个会话可以设置超时时间 心跳结束则session过期 session过期后临时节点znode会被抛弃 watcher机制简介 针对每个节点的操作都会有一个监督者watcher 监控的某个对象发生变化触发watcher事件 zk中的watcher是一次性的，触发后立即销毁 父节点，子节点的增删改都会触发watcher 不同类型的操作触发的watcher事件不同： 节点创建件 节点删除时间 节点数据变化事件 watcher事件类型父节点watcher事件 创建父节点后触发 NodeCreated 修改父节点触发 NodeDataChanged 删除父节点触发NodeDeleted 子节点watcher事件 ls为父节点设置watcher，创建子节点触发：NodeChildrenChanged ls为父节点设置watcher，删除子节点触发：NodeChildrenChanged 为什么子节点的创建与删除的watcher事件是相同的：对于父节点而言只关心子节点是否发生变化，而不会去关心变化的类型 ls为父节点设置watcher，修改子节点不触发事件，只有把子节点当成父节点的时候才能触发watcher事件：NodeDataChanged watcher使用场景 统一资源配置 ACL（Access control lists）权限控制简介 针对节点设置读写权限，保障数据安全性 权限permission可以指定不同的权限范围及角色 ACL命令行 语法 用途 图片 getAcl path 获取某节点acl权限信息 setAcl path acl 设置某节点acl权限信息 addauth scheme auth 输入认证授权信息，注册时输入明文密码，zk系统加密保存 super 权限添加 123456781.编辑./zkServer.sh文件vim ./zkServer.sh2.找到下面的内容nohup &quot;$JAVA&quot; &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; \3.在\前面添加内容&quot;-Dzookeeper.DigestAuthenticationPro vider.superDigest=geekerit:rGhia4aR7QpOxSk4boNgq5DTEf8=&quot;4.重启zookeeper服务./zkServer.sh restart ACL构成 zk的ACL通过[scheme:id:permissions]来构成权限列表 | 字段 | 含义 || ———– | ————– || scheme | 采用的权限机制 || id | 允许访问的用户 || permissions | 权限组合字符串 | scheme world：只有一个id，anyone，组合写法：world:anyone:[permissions] auth：认证登录，注册用户有权限即可，组合形式：auth:user:password:[permissions] digest：需要对密码加密才能访问，组合形式：digest:username:BASE64(SHA1(password)):[permissions] ip：当设置为ip指定ip指定的ip地址，限制ip访问，组合形式：ip:192.168.1.1:[permissions] super：炒鸡管理员，拥有所有权限 permissions 权限字符串缩写crdwa | 字符串 | 命令 || —— | ————— || CREATE | 创建子节点 || READ | 获取节点/子节点 || WRITE | 设置节点数据 || DELETE | 删除子节点 || ADMIN | 设置权限 | 使用场景 开发测试环境分离 生产环境指定ip的服务访问相关节点 zk四字命令简介 通过自身提供的简写命令与服务器进行交互 需要安装nc命令 使用 stat 查看zk的状态信息，是否mode 1echo stat | nc localhost 2181 ruok 查看当前zkServer是否启动，返回imok 1echo ruok | nc localhost 2181 dump 列出未经处理的会话和临时节点 1echo dump | nc localhost 2181 conf 查看服务器配置 1echo conf | nc localhost 2181 cons 展示连接到服务器的客户端信息 1echo cons | nc localhost 2181 envi 环境变量 1echo envi | nc localhost 2181 mntr 监控zk的健康信息 1echo mntr | nc localhost 2181 wchs 展示watch的信息 1echo wchs | nc localhost 2181 wchc 查看session与watch的信息 1echo wchc | nc localhost 2181 wchp 查看path与watch的信息 1echo wchp | nc localhost 2181 注意使用wchc与wchp命令需要先在配置项中增加白名单设置(详细说明参照官方文档–Administrator’s Guide 中的4lw.commands.whitelist) 1234567&gt; 1. 编辑配置文件&gt; vim zoo.cfg&gt; 2. 添加如下命令(复制，手打注意不是4后边不是数字1而是字母l)&gt; 4lw.commands.whitelist=*&gt; 3. 重启服务&gt; ./zkServer restart &gt;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper安装]]></title>
    <url>%2F2018%2F11%2F11%2Fmicroservice%2Fdubbo%2Fzookeeper%2F2018-11-11-zookeeper%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[zookeeper安装单机服务安装1.下载zookeeper(3.4.13) 官方链接 网盘下载2.上传至服务器并解压文件 1tar -xzvf zookeeper-3.4.13.tar.gz 3.cd 至zookeeper目录下创建data、logs目录123cd zookeeper-3.4.13mkdir datamkdir logs 4.创建cfg文件12345671. 创建zoo.cfgvim zoo.cfg2. 进行单机版配置tickTime=2000dataDir=/usr/local/zookeeper/zookeeper-3.4.13/datadataLogDir=/usr/local/zookeeper/zookeeper-3.4.13/logsclientPort=2181 5.启动命令121.切换至bin目录下2.使用./zkServer.sh进行相关操作 命令 解释 ./zkServer.sh start 启动 ./zkServer.sh stop 停止 ./zkServer.sh restart 重启 ./zkServer.sh status 查看状态 伪集群安装1.重命名文件夹1mv zookeeper3.4.13 zookeeper1 2.修改zoo.cfg文件12345678dataDir=/usr/local/zookeeper/zookeeper1/datadataLogDir=/usr/local/zookeeper/zookeeper1/logsclientPort=2181initLimit=5syncLimit=2server.1=127.0.0.1:2888:3888server.2=127.0.0.1:4888:5888server.3=127.0.0.1:6888:7888 3.创建myid文件123451. 定位至zoo.cfg设置的dataDir文件夹下：cd data/2. 创建myid文件vim myid输入 1 (这里一定要与zoo.cfg中的server名后的数字保持一致) 4.复制并修改相关配置文件12341. 复制文件夹cp -r zookeeper1 zookeeper2cp -r zookeeper1 zookeeper32. 修改关键内容，data目录下的myid文件，修改为服务后的数字 集群安装1. 上传zookeeper文件到三台虚拟机中并进行解压1tar -xzvf zookeeper-3.4.13.tar.gz 2.在解压的zookeeper文件夹下创建data，logs两个目录；1mkdir data logs 3.在conf文件夹下创建zoo.cfg文件12cd conf/vim zoo.cfg 4. 在zoo.cfg中输入内容12345678dataDir=/usr/local/zookeeper/zookeeper3.4.13/datadataLogDir=/usr/local/zookeeper/zookeeper3.4.13/logsclientPort=2181initLimit=5syncLimit=2server.1=192.168.1.4:2888:3888server.2=192.168.1.5:2888:3888server.3=192.168.1.6:2888:3888 5. 在data目录下创建myid文件，文件内容为server后的数字，例如192.168.1.4的zoo.cfg中server后的数字为1，则在4的机器data目录下创建myid文件，文件内容输入数字1即可12cd data/vim myid 6.检查每台机器的防火墙的状态，我这里是虚拟机为了方便操作，我直接将防火墙关闭了，生产环境请放行端口进行操作1234561. 查看防火墙状态systemctl status firewalld2. 关闭防火墙systemctl stop firewalld3. 禁止防火墙开机启动systemctl disable firewalld 7.启动每台机器的实例并查看状态12341. 启动zookeeper服务./zkServer.sh start 2. 查看每台机器的服务状态./zkServer.sh status zookeeper目录及命令介绍zookeeper主要目录结构 目录 用途 bin 主要的运行命令 conf 配置文件 contrib 附加功能 dist-maven mvn编译后的目录 docs 文档 lib 依赖JAR包 recipes 案列demo src 源码 zoo.cfg配置 配置项 含义 tickTime 计算的时间单元 initTime 允许从节点连接并同步到主节点的初始化连接时间，以tickTime的倍数来表示，用于集群 syncLimit master主节点与从节点之间发送消息请求和应答的时间长度（心跳机制） dataDir 数据目录 dataLogDir 日志目录，不建议使用/tmp临时目录 clientPort 连接端口 eg: 123456tickTime=2000dataDir=/usr/local/zookeeper/zookeeper1/datadataLogDir=/usr/local/zookeeper/zookeeper1/logsclientPort=2181initLimit=5syncLimit=2]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将java项目加入系统服务]]></title>
    <url>%2F2018%2F11%2F06%2FJava%2F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F2018-11-06-%E5%B0%86Java%E9%A1%B9%E7%9B%AE%E5%8A%A0%E5%85%A5%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[将java项目加入系统服务到/usr/lib/systemd/system文件夹下编辑服务脚本1cd /usr/lib/systemd/system 脚本内容如下1234567[Unit]Description=test_api serviceWants=network.target[Service]User=nobodyType=forkingExecStart=/bin/sh -c &apos;nohup /usr/local/java/jdk8/bin/java -jar /home/app/member/fordearme-member-system-0.0.1-SNAPSHOT.jar &amp;&apos; ExecStart指定脚本启动命令，注意java命令最好使用绝对路径执行 命令 作用 systemctl enable ***.service 服务开机自启 systemctl start ***.service 启动服务 systemctl status ***.service 查看服务状态 systemctl stop ***.service 停止服务]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot项目添加过滤器]]></title>
    <url>%2F2018%2F11%2F06%2Fframework%2Fspringboot%2F2018-11-06-springboot%E6%B7%BB%E5%8A%A0%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[springboot项目添加过滤器第一种方式创建过滤器类12345678910111213141516171819public class MyFilter implements Filter &#123; private static final Logger logger = LoggerFactory.getLogger(MyFilter.class); @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; logger.info("this is MyFilter,url :"+request.getRequestURI()); filterChain.doFilter(servletRequest, servletResponse); &#125; @Override public void destroy() &#123; &#125; 在过滤器类上添加注解@WebFilter(urlPatterns = “/*”)在启动类上添加包扫描注解@ServletComponentScan(basePackages ={“filter所在包名”})第二种方式同第一种方式，创建自己的过滤器类，但是不要使用注解声明为filter类创建web配置类，将自定义的filter注册为bean1234567891011121314@Configurationpublic class WebConfiguration &#123; @Bean public FilterRegistrationBean testFilterRegistration() &#123; FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new MyFilter()); registration.addUrlPatterns("/*"); registration.setName("MyFilter"); registration.setOrder(6); return registration; &#125;&#125; 过滤器实例1234567891011121314151617181920212223/** * 创建字符过滤器 * @return */ @Bean public FilterRegistrationBean charsetFilter()&#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); // 定义字符编码过滤器 CharacterEncodingFilter characterEncodingFilter = new CharacterEncodingFilter(); characterEncodingFilter.setForceEncoding(true); // 设置编码格式为UTF-8 characterEncodingFilter.setEncoding("UTF-8"); // 将过滤器注册 filterRegistrationBean.setFilter(characterEncodingFilter); // 创建过滤规则集合 List&lt;String&gt; patterns = new ArrayList&lt;&gt;(); // 设置过滤规则为全部过滤 patterns.add("/*"); // 加入过滤规则 filterRegistrationBean.setUrlPatterns(patterns); return filterRegistrationBean; &#125; 上述字符编码过滤器只有在spring.http.encoding.enabled=flase时才会生效]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>过滤器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot集成dubbo时默认日志依赖与zookeeper日志依赖冲突解决]]></title>
    <url>%2F2018%2F11%2F05%2Fframework%2Fspringboot%2F2018-11-05-springboot%E9%9B%86%E6%88%90dubbo%E6%97%A5%E5%BF%97%E4%BE%9D%E8%B5%96%E5%86%B2%E7%AA%81%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[springboot集成dubbo时默认日志依赖与zookeeper日志依赖冲突解决异常信息12345678910111213141516171819Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/F:/fordearme/utils/maven/apache-maven-3.5.3/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar). If you are using WebLogic you will need to add &apos;org.slf4j&apos; to prefer-application-packages in WEB-INF/weblogic.xml: org.slf4j.impl.Log4jLoggerFactory at org.springframework.util.Assert.instanceCheckFailed(Assert.java:655) at org.springframework.util.Assert.isInstanceOf(Assert.java:555) at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLoggerContext(LogbackLoggingSystem.java:286) at org.springframework.boot.logging.logback.LogbackLoggingSystem.beforeInitialize(LogbackLoggingSystem.java:102) at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationStartingEvent(LoggingApplicationListener.java:217) at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:196) at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:127) at org.springframework.boot.context.event.EventPublishingRunListener.starting(EventPublishingRunListener.java:69) at org.springframework.boot.SpringApplicationRunListeners.starting(SpringApplicationRunListeners.java:48) at org.springframework.boot.SpringApplication.run(SpringApplication.java:302) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at com.geekerit.springbootdubboprovider.SpringbootDubboProviderApplication.main(SpringbootDubboProviderApplication.java:11)Process finished with exit code 1 原因分析：由于集成dubbo需要引入zookeeper的客户端的依赖，但是zookeeper客户端的依赖中存在slf4j以及log4j的日志依赖，而springboot默认集成的日志依赖为logback，所以需要根据自己的偏好将其中某一日志依赖进行排除。 排除slf4j日志依赖： 1234567891011121314151617&lt;!--zookeeper依赖--&gt; &lt;!-- https://mvnrepository.com/artifact/com.101tec/zkclient --&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; 排除logback日志依赖： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 依赖图： zookeeper日志依赖 springboot 默认日志依赖 参考博客 查看maven依赖树 解决slf4j 冲突]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>异常解决</tag>
        <tag>日志冲突</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装配置Redis4]]></title>
    <url>%2F2018%2F11%2F03%2Fnosql%2Fredis%2F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F2018-11-03-CentOS7%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AERedis4%2F</url>
    <content type="text"><![CDATA[准备安装Redis安装编译环境1yum install gcc-c++ 下载上传Redis源码安装包 redis官网链接 redis4网盘链接 解压文件1tar -xzvf redis-4.0.2.tar.gz 编译redis1234# cd 至解压完的redis目录下cd redis-4.0.2# 进行编译make 安装启动安装redis12# PREFIX:安装Redis到指定文件夹下make PREFIX=/usr/local/redis install 修改相关配置修改监听地址复制Redis目录下的redis.conf文件到上一级目录的bin目录下并修改相关配置(最好不要修改原有的配置文件或者将原配置文件进行备份) 1234# 查看自己的服务器网卡地址ifconfig# 修改bind的地址为上述查询网卡地址，注意这里不是设置你请求redis的客户端IP地址，而是设置自己的服务器的网卡地址，同时不建议为了省事将bind地址设置为0.0.0.0，增加自己的服务器风险 bind 127.0.0.1 172.*.*.* 守护进程设置允许Redis服务以守护进程方式启动 12# By default Redis does not run as a daemon.daemonize yes 启动Redis服务12# 指定配置文件启动redis服务(前台启动，关闭窗口服务停止)./redis-server redis.conf 测试连接本地客户端连接测试1234567891011# 如果没有提前设置过redis的密码，可以直接连接使用./redis-cli# 设置密码的情况下两种连接方法 # 第一种： # 首先使用命令连接服务 ./redis-cli # 使用命令进行密码验证 AUTH yourpassword # 第二种： # 连接时直接指定连接服务的密码 ./redis-cli -a yourpassword 设置了Redis连接密码需要先进行密码验证才能使用客户端 远程Redis可视化工具连接测试 可视化工具redis-desktop-Manager网盘链接 注册Redis为系统服务进入系统文件目录下1cd /lib/systemd/system 创建Redis的服务文件1vim redis.service 复制以下内容到文件中12345678[Unit]Description=redis serviceWants=network.target[Service]Type=forkingExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/bin/redis.conf[Install]WantedBy=multi-user.target 设置开机启动1systemctl enable redis 启动查看Redis12345678# 启动redis服务systemctl start redis# 查看redis的服务状态systemctl status redis# 停止redis服务systemctl stop redis# 重启redis服务systemctl restart redis 参考博文 阿里云 CentOS7安装redis4.0.9并开启远程访问]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装配置 JDK8]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F2018-11-03-CentOS7%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEJDK8%2F</url>
    <content type="text"><![CDATA[安装准备下载JDK源码包 官网链接 JDK8网盘链接 创建java目录12cd /usr/local/mkdir java 开始安装上传文件解压文件包1tar -xzvf jdk-8u161-linux-x64.tar.gz -C /usr/local/java 查看文件1234定位至java文件夹下cd /usr/local/java查看目录下的文件ll 重命名文件夹123456重命名为jdk8(便于之后环境配置，非必须)mv jdk1.8.0_161/ jdk8定位至jdk目录下cd jdk8查看当前路径并复制输出结果pwd 配置环境变量编辑环境变量文件使用 vim /etc/profile 在文件最后追加以下java变量配置 12345# 将目录更换为自己的JDK安装目录(第二步最后的文件路径)export JAVA_HOME=/usr/local/java/jdk8 export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 刷新配置文件1source /etc/profile 查看 Java 版本 使用 java -version 验证安装是否成功]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>环境配置</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka入门]]></title>
    <url>%2F2018%2F11%2F01%2FMQ%2Fkafka%2F2018-11-01-centos%E5%AE%89%E8%A3%85kafka%2F</url>
    <content type="text"><![CDATA[下载zookeeper(3.4.13) 官方链接 网盘下载 上传至服务器并解压文件 1tar -xzvf zookeeper-3.4.13.tar.gz cd 至zookeeper目录下创建data、logs目录 123cd zookeeper-3.4.13mkdir datamkdir logs 创建cfg文件 1234tickTime=2000dataDir=/usr/local/zookeeper/zookeeper-3.4.13/datadataLogDir=/usr/local/zookeeper/zookeeper-3.4.13/logsclientPort=2181 启动命令 121.切换至bin目录下2.使用./zkServer.sh进行相关操作 命令 解释 ./zkServer.sh start 启动 ./zkServer.sh stop 停止 ./zkServer.sh restart 重启 ./zkServer.sh status 查看状态 重命名并复制文件夹 1mv zookeeper3.4.13 zookeeper1 修改zoo.cfg文件 12345678dataDir=/usr/local/zookeeper/zookeeper1/datadataLogDir=/usr/local/zookeeper/zookeeper1/logsclientPort=2181initLimit=5syncLimit=2server.1=127.0.0.1:2888:3888server.2=127.0.0.1:4888:5888server.3=127.0.0.1:6888:7888 创建myid文件 123cd data/vim myid输入 1 (这里与server名保持一致) 复制并修改相关配置文件 12cp -r zookeeper1 zookeeper2cp -r zookeeper1 zookeeper3 1234567891011121314151617181. 生产主题 ./kafka-console-producer.sh --broker-list localhost:9092 --topic test1 2. 订阅主题 ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test1 3. 启动kafka ./kafka-server-start.sh ../config/server.properties4. 查看已发布的主题./kafka-topics.sh --zookeeper localhost:2181 --list5. 查看主题描述./kafka-topics.sh --zookeeper localhost:2181 --describe --topic test16. 发布主题./kafka-topics.sh --zookeeper localhost:2181 --create --topic test1 --partitions 3 --replication-factor 1 kafka启动故障 1231.删除 /tmp/kafka-logs2.netstat -lnp|grep 90923.重新启动 待补充通过docker安装zookeeper与kafka并进行通信，提供服务 参考： 分布式Zookeeper安装搭建详解 zookeeper安装教程（zookeeper3.4.5为例）]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>消息中间件</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot启动流程概述]]></title>
    <url>%2F2018%2F07%2F15%2Fframework%2Fspringboot%2FSpringBoot%E5%8A%A0%E8%BD%BD%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[启动流程创建SpringApplication对象1234567public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) &#123; return run(new Class[]&#123;primarySource&#125;, args);&#125;public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return (new SpringApplication(primarySources)).run(args);&#125; 12345678910111213141516public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; // 确保主配置类不为空 Assert.notNull(primarySources, "PrimarySources must not be null"); // 保存主配置类 this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); // 确定当前应用的类型（NONE,SERVLET,REACTIVE） this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 从类路径下找到META-INF/spring.factories配置中的所有ApplicationContextInitializer然后保存起来 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); // 从类路径下找到META-INF/spring.factories配置中的所有ApplicationListener然后保存起来 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 从多个配置类中找到带有main()方法的启动类 this.mainApplicationClass = deduceMainApplicationClass();&#125; 123456789101112131415private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) &#123; return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] &#123;&#125;);&#125;private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); // Use names and ensure unique to protect against duplicates Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125; 1234567891011121314151617181920212223242526272829303132333435public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); return loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList());&#125;private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123; MultiValueMap&lt;String, String&gt; result = cache.get(classLoader); if (result != null) &#123; return result; &#125; try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); result = new LinkedMultiValueMap&lt;&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryClassName = ((String) entry.getKey()).trim(); for (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123; result.add(factoryClassName, factoryName.trim()); &#125; &#125; &#125; cache.put(classLoader, result); return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException("Unable to load factories from location [" + FACTORIES_RESOURCE_LOCATION + "]", ex); &#125;&#125; 调用run()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public ConfigurableApplicationContext run(String... args) &#123; // 创建容器停止的监听 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); // 从类路径下META-INF/spring.factories中获取SpringApplicationRunListeners对象 SpringApplicationRunListeners listeners = getRunListeners(args); // 获取所有的SpringApplicationRunListener的starting()方法 listeners.starting(); try &#123; // 获取命令行的参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); // 准备环境，创建环境完成后回调SpringApplicationRunListener的environmentPrepared()方法表示环境准备完成 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); // 打印程序banner Banner printedBanner = printBanner(environment); // 创建ApplicationContext，根据应用类型创建相应的IOC容器 context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); // 准备上下文环境 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 刷新容器，IOC容器初始化（如果是web应用还会创建嵌入式的TOMCAT） refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; // 所有的SpringApplicationRunListener调用started()方法 listeners.started(context); // 从IOC容器中获取所有的ApplicationRunner以及CommandLineRunner进行回调 callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; // 整个SpringBoot容器启动完成后返回启动的IOC容器 return context;&#125; 准备环境 123456789101112131415private ConfigurableEnvironment prepareEnvironment( SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // Create and configure the environment ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); listeners.environmentPrepared(environment); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()) .convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment;&#125; 创建ApplicationContext 123456789101112131415161718192021222324protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; switch (this.webApplicationType) &#123; case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( "Unable create a default ApplicationContext, " + "please specify an ApplicationContextClass", ex); &#125; &#125; return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; 准备上下文环境 12345678910111213141516171819202122232425262728293031private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; // 将environment保存到IOC中 context.setEnvironment(environment); postProcessApplicationContext(context); // 回调之前获取的所有ApplicationContextInitializer的initialize()方法 applyInitializers(context); // 回调所有的SpringApplicationRunListener的contextPrepared()方法 listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton("springApplicationArguments", applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton("springBootBanner", printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; // Load the sources Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, "Sources must not be empty"); load(context, sources.toArray(new Object[0])); // 所有方法完成后回调所有的SpringApplicationRunListener的contextLoaded()方法 listeners.contextLoaded(context);&#125; 12345678protected void applyInitializers(ConfigurableApplicationContext context) &#123; for (ApplicationContextInitializer initializer : getInitializers()) &#123; Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument( initializer.getClass(), ApplicationContextInitializer.class); Assert.isInstanceOf(requiredType, context, "Unable to call initializer."); initializer.initialize(context); &#125;&#125; 12345public void contextPrepared(ConfigurableApplicationContext context) &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; listener.contextPrepared(context); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; callRunners 1234567891011121314private void callRunners(ApplicationContext context, ApplicationArguments args) &#123; List&lt;Object&gt; runners = new ArrayList&lt;&gt;(); runners.addAll(context.getBeansOfType(ApplicationRunner.class).values()); runners.addAll(context.getBeansOfType(CommandLineRunner.class).values()); AnnotationAwareOrderComparator.sort(runners); for (Object runner : new LinkedHashSet&lt;&gt;(runners)) &#123; if (runner instanceof ApplicationRunner) &#123; callRunner((ApplicationRunner) runner, args); &#125; if (runner instanceof CommandLineRunner) &#123; callRunner((CommandLineRunner) runner, args); &#125; &#125;&#125; SpringBoot事件监听机制配置在META-INF/spring.factories ApplicationContextInitializer SpringApplicationRunListener IOC容器中 ApplicationRunner CommandLineRunner 案例实现 在应用启动时将地址编码对照列表存储在Redis中，实现数据的预加载。 1234567891011121314151617@Componentpublic class MyCommandLineRunner implements CommandLineRunner &#123; @Autowired private RedisTemplate redisTemplate; @Autowired private IAddressMetaService addressMetaService; @Override public void run(String... strings) throws Exception &#123; List&lt;AddressMeta&gt; addressMetas = addressMetaService.addressMetaList(); for (int i = 0; i &lt; addressMetas.size(); i++) &#123; redisTemplate.opsForValue().set("address" + addressMetas.get(i).getValue(),addressMetas.get(i).getName()); &#125; &#125;&#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>框架学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池创建以及拒绝策略]]></title>
    <url>%2F2018%2F06%2F11%2FJava%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fthread%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[什么是线程池 线程池是一种多线程处理形式，处理过程中将任务添加到队列，然后在创建线程后自动启动这些任务。线程池线程都是后台线程。每个线程都使用默认的堆栈大小，以默认的优先级运行，并处于多线程单元中。如果某个线程在托管代码中空闲（如正在等待某个事件），则线程池将插入另一个辅助线程来使所有处理器保持繁忙。如果所有线程池线程都始终保持繁忙，但队列中包含挂起的工作，则线程池将在一段时间后创建另一个辅助线程但线程的数目永远不会超过最大值。超过最大值的线程可以排队，但他们要等到其他线程完成后才启动。 为什么需要创建线程池 Thread 是一个重量级的资源，创建、启动以及销毁都是比较耗费系统资源的，为了重复利用线程，提高系统效率。 如何创建线程池通过ThreadPoolExecutor的构造方法创建线程池123456789101112131415161718192021222324252627282930313233/* * int corePoolSize, 线程池核心线程数 * int maximumPoolSize, 最大线程数 * long keepAliveTime, 当线程数量超出线程池的核心数量时，在超出指定空闲时间后会回收空闲线程 * TimeUnit unit, 时间单位 * BlockingQueue&lt;Runnable&gt; workQueue, 阻塞队列，任务会先交给阻塞队列然后才会被执行 * ThreadFactory threadFactory, 线程工厂，指定通过何种方式创建线程 * RejectedExecutionHandler handler 拒绝策略，当线程池数量达到最大线程数并且阻塞队列已满时会执行拒绝策略 */public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; API参数解读当在方法execute（Runnable）中提交新任务，并且运行的线程少于corePoolSize时，即使其他工作线程处于空闲状态，也会创建一个新线程来处理该请求。如果有多个corePoolSize但运行的maximumPoolSize线程少于maximumPoolSize，则只有在队列已满时才会创建新线程。通过设置corePoolSize和maximumPoolSize，可以创建固定大小的线程池。 如果池当前具有多个corePoolSize线程，则多余的线程如果空闲时间超过keepAliveTime则终止（请参阅getKeepAliveTime（TimeUnit））。这提供了一种在不主动使用池时减少资源消耗的方法。如果池稍后变得更活跃，则将构造新线程。也可以使用方法setKeepAliveTime（long，TimeUnit）动态更改此参数。 如何理解线程池创建的多个参数我们创建线程池的目的是为了更加方便的创建线程，达到线程复用的目的；同时通过线程池创建线程能够更好地做到线程的管理工作，防止资源浪费。 明确了初衷之后那我们创建线程池一定首先要去指定线程工厂，告诉线程池通过何种方式帮助我们创建线程，同时还需要知道我们应该创建多少核心线程与最大线程，当新任务提交的时候分为以下几种情况： 线程池中的线程没有超出核心线程数量，直接新建线程来运行新任务 线程池中的线程已经超出核心线程数量，查看等待队列 任务等待队列容量未满时将新任务放入等待队列中 任务等待队列容量已满时查看线程池中的线程数量是否超出了最大线程数 未超出最大线程数时创建线程执行任务 超出最大线程数时执行预定义的拒绝策略 并且在线程池中的线程数量超出核心线程数量时需要告诉线程池在多久的空闲时间内回收空闲线程。 // TODO 待添加ThreadPoolExecutor源码解读 通过Executors工具类提供的一系列的方法创建线程池newFixedThreadPool作用创建指定核心（最大）线程数的线程池 特点 核心线程数与最大线程数保持一致，这会导致两种情况：一种是在线程池的调度中会以10个线程为1组执行任务，第二种是即使任务全部执行结束，线程池也不会自动销毁，虽然最大空闲时间为0毫秒，但是由于其最大线程数并没有超过核心线程数，所以并不会回收空闲线程，使用完成后应该对其执行shutdown()方法进行关闭操作 阻塞队列的最大容量为Integer.MAX_VALUE 线程工厂为Executors类中的默认线程工厂 拒绝策略为AbortPolicy()，即任务队列满时抛出异常告诉调用者该任务将不被执行 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 使用场景newWorkStealingPool作用创建与CPU核心数相同数量线程的线程池 特点 利用无参构造创建的线程池，核心线程数为CPU核心数量 在任务线程未处理完时会将任务放到阻塞队列中 任务结束后会自动销毁 123456public static ExecutorService newWorkStealingPool() &#123; return new ForkJoinPool (Runtime.getRuntime().availableProcessors(), ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true);&#125; 使用场景newSingleThreadExecutor作用创建只有一个核心线程的线程池 特点 核心线程数与最大线程数相同都为1 未执行的任务会被提价到阻塞队列中，最大长度为Integer.MAX_VALUE newSingleThreadExecutor任务执行完成一样不会自动销毁，其实其实现就类似于newFixedThreadPool(1) 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; newSingleThreadExecutor与手动开启一个线程执行任务的区别 一个线程执行完任务之后生命周期就会结束，而单线程的线程池会一直存活，可以有效实现线程复用 手动创建的线程并不能将任务去缓存到任务队列中而单线程的线程池可以缓存任务，将未执行任务放入阻塞队列中等待执行 使用场景newCachedThreadPool作用创建核心线程数为0的线程池 特点 核心线程数为0，在任务线程全部结束60秒后，线程池发现所有线程处于空闲状态，将会回收所有线程，则线程池会自动销毁 当中执行的任务的周期应该非常短，因为在每次提交任务时其发现线程池中没有可用线程，就会自动创建一个线程执行任务（最大线程数为Integer.MAX_VALUE）,而其阻塞队列为只能存放一个任务的队列，所以该线程池不会将任务暂存下来，只有在60秒（默认时间）后线程池发现有空闲线程，才会复用线程去处理队列中的任务 如果提交的任务的执行周期特别长，该线程池会不断创建线程造成系统发生栈内存溢出 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 使用场景 线程池的内置拒绝策略AbortPolicy在线程池内的任务线程已经达到最大线程数并且线程池的任务队列已满时，线程池会抛出异常告诉调用者将提交的新任务拒绝执行，但是线程池不会关闭 ，仍然会正常执行完任务线程以及队列中的任务。 123456789101112131415/** * 测试AbortPolicy拒绝策略 */private static void testAbortPolicy() &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(1, 2,30, TimeUnit.SECONDS,new ArrayBlockingQueue&lt;&gt;(1),(ThreadFactory) Thread::new,new ThreadPoolExecutor.AbortPolicy()); IntStream.range(0,3).boxed().forEach(i -&gt; threadPoolExecutor.execute(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;)); threadPoolExecutor.execute(() -&gt; System.out.println("x"));&#125; DiscardPolicy直接将任务丢弃，调用者收不到任何信息，如果执行的任务比较重要在使用时需要注意 12345678910111213141516private static void testDiscardOldestPolicy() &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(1, 2, 30, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.DiscardPolicy()); IntStream.range(0, 3).boxed().forEach(i -&gt; threadPoolExecutor.execute(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;)); threadPoolExecutor.execute(() -&gt; System.out.println("x"));&#125; CallerRunsPolicy调用者自己执行任务线程，不使用线程池中的资源执行任务 12345678910111213141516171819private static void testCallerRunsPolicy() &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(1, 2, 30, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.CallerRunsPolicy()); IntStream.range(0, 3).boxed().forEach(i -&gt; threadPoolExecutor.execute(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;)); threadPoolExecutor.execute(() -&gt; &#123; System.out.println("x"); System.out.println(Thread.currentThread().getName()); &#125;);&#125; DiscardOldestPolicy丢弃队列中较老的任务，转而执行新提交的任务 1234567891011121314151617181920private static void testDiscardOldestPolicy() &#123; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(1, 2, 30, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1), (ThreadFactory) Thread::new, new ThreadPoolExecutor.DiscardOldestPolicy()); IntStream.range(0, 3).boxed().forEach(i -&gt; threadPoolExecutor.execute(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(5); System.out.println("i am from lambda."); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;)); threadPoolExecutor.execute(() -&gt; &#123; System.out.println("x"); System.out.println(Thread.currentThread().getName()); &#125;);&#125; 线程池工作原理1The main pool control state, ctl, is an atomic integer packingtwo conceptual fields workerCount, indicating the effective number of threads runState, indicating whether running, shutting down etcIn order to pack them into one int, we limit workerCount to(2^29)-1 (about 500 million) threads rather than (2^31)-1 (2billion) otherwise representable. If this is ever an issue inthe future, the variable can be changed to be an AtomicLong,and the shift/mask constants below adjusted. But until the needarises, this code is a bit faster and simpler using an int.The workerCount is the number of workers that have beenpermitted to start and not permitted to stop. The value may betransiently different from the actual number of live threads,for example when a ThreadFactory fails to create a thread whenasked, and when exiting threads are still performingbookkeeping before terminating. The user-visible pool size isreported as the current size of the workers set.The runState provides the main lifecycle control, taking on values: RUNNING: Accept new tasks and process queued tasks SHUTDOWN: Don&apos;t accept new tasks, but process queued tasks STOP: Don&apos;t accept new tasks, don&apos;t process queued tasks, and interrupt in-progress tasks TIDYING: All tasks have terminated, workerCount is zero, the thread transitioning to state TIDYING will run the terminated() hook method TERMINATED: terminated() has completedThe numerical order among these values matters, to allowordered comparisons. The runState monotonically increases overtime, but need not hit each state. The transitions are:RUNNING -&gt; SHUTDOWN On invocation of shutdown(), perhaps implicitly in finalize()(RUNNING or SHUTDOWN) -&gt; STOP On invocation of shutdownNow()SHUTDOWN -&gt; TIDYING When both queue and pool are emptySTOP -&gt; TIDYING When pool is emptyTIDYING -&gt; TERMINATED When the terminated() hook method has completedThreads waiting in awaitTermination() will return when thestate reaches TERMINATED.Detecting the transition from SHUTDOWN to TIDYING is lessstraightforward than you&apos;d like because the queue may becomeempty after non-empty and vice versa during SHUTDOWN state, butwe can only terminate if, after seeing that it is empty, we seethat workerCount is 0 (which sometimes entails a recheck -- seebelow).]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础之SQL优化]]></title>
    <url>%2F2018%2F06%2F11%2Fdatabase%2FMySQL%2FSQL%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[mysql 忘记密码 可能导致数据查询慢的原因 性能低 执行时间长 SQL语句问题（连接查询） 索引失效 服务器参数设置不合理 SQL优化主要就是在优化索引 分析SQL的执行计划语法explain，可以模拟SQL优化器执行SQL语句，从而让开发人员了解SQL的执行情况 参数详细说明id编号 编号相同时从上到下顺序执行，上下顺序根据表中的记录数不同而不同，理论依据是笛卡尔积，编号不同时编号越大的先执行 select_type查询类型 PRIMARY包含子查询SQL中的主查询（最外层） SUBQUERY包含子查询SQL中的子查询 SIMPLE简单查询（不包含子查询、union） DERIVED衍生查询（使用到了临时表，1.在from查询子查询中只有一张表；2.在from子查询中，如果有table1 union table2,则table1就是derived） UNION若第二个SELECT出现在UNION之后，则被标记为UNION UNION RESULT从UNION表中获取结果的SELECT table表 显示这一行的数据是关于那张表的 type类型 system&gt;const&gt;eq_ref&gt;ref&gt;range&gt;inedx&gt;all system(理想情况) 只有一条数据的系统表或者衍生表只有一条数据的主查询 const(理想情况) 只能查询一条数据的SQL，用于primary key或者unique 索引 eq_ref 唯一性索引，对于每个索引键的查询，返回匹配唯一行数据（有且只有一个，不能多也不能为0），常见于唯一索引和主键索引。 ref 非唯一性索引，对于每个索引键的查询，返回匹配的所有行 range 检索指定范围的行，where后面是范围查询（between，&gt;,&lt;,&lt;=,&gt;=,in有时候会失效，转为无索引all） inedx 查询全部索引中数据 all 查询表中全部数据 possible_keys预计用到的索引 key实际使用的索引 key_len索引字段的最大可能长度 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。 如果索引字段可以为null，则会使用1个字节用于标识。MySQL会用2个字节标识该字段为变长字段（varchar） ref表与表之间的引用关系,指明当前表的参照字段 rows通过索引查询的数据量 Extra额外信息 using filesort:性能消耗大，需要额外的一次排序，一般出现在order by语句中 对于单索引来说，如果排序的字段与查找的字段为同一字段，则不会出现using filesort，建议where哪些字段就order by哪些字段； 复合索引不能跨列（最佳左前缀），where和order by按照复合索引使用，不要跨列或者无序使用 using temporary：性能损耗大，用到了临时表。一般出现在group by语句中，查询哪些列，就根据哪些列进行分组。已经有表了但是不适用，必须再来一张表。 using index：性能提升，覆盖索引（不读取原文件，只从索引文件中获取数据，不需要回表查询），只要使用到的列全部都在索引中，就是索引覆盖 如果用到了索引覆盖，会对possible_keys 与key造成影响 如果没有where，则索引只出现在key中 如果有where，则索引出现在possible_keys 与key中 using where :需要回表查询，查询列中存在索引中不存在的列 impossible where：where字句永远为false MySQL查询优化会干扰优化 如果（a,b,c,d）复合索引和使用的顺序全部一致（且不跨列使用），则复合索引全部使用，如果部分一致，则使用部分索引。 SQL优化实战单表优化12345678910111213141516171819202122232425262728293031# 创建表CREATE TABLE book( bid int(4) primary key, name varchar(20) not null, authorid int(4) not null, publicid int(4) not null, typeid int(4) not null); # 插入测试数据INSERT INTO book VALUES (1,&apos;Java&apos;,1,1,3);INSERT INTO book VALUES (2,&apos;SQL&apos;,2,4,2);INSERT INTO book VALUES (3,&apos;jQuery&apos;,1,2,4);INSERT INTO book VALUES (4,&apos;spring&apos;,3,3,1);# 需要查询的数据SELECT bid FROM book WHERE authorid=1 AND typeid in (3,4) ORDER BY typeid DESC;# 查看执行计划explain SELECT bid FROM book WHERE authorid=1 AND typeid in (3,4) ORDER BY typeid DESC;# 第一次创建索引（index_bat）ALTER TABLE book ADD INDEX index_bat (bid,authorid,typeid);# 第二次创建索引ALTER TABLE book ADD INDEX index_atb (authorid,typeid,bid);# 删除废弃索引DROP INDEX index_bat ON book; 未创建索引时进行查询SQL执行情况 未使用索引 需要进行回表查询 需要进行文件内排序 首次创建索引后执行计划 覆盖索引 查询级别提升至index 依旧需要文件内排序 优化索引后执行计划 覆盖索引 查询级别提升至ref 不再需要进行文件内排序 存在回表查询的可能（查询typeid时无法命中索引-in范围查询） 索引一旦进行升级优化，需要将废弃的索引进行删除，防止出现查询时干扰 最佳左前缀原则，需要保持索引的定义与使用的顺序一致性 索引需要逐步进行优化 将包含in的范围查询放在where字句的后边，防止索引失效 两表优化123456789101112131415161718192021222324252627282930# 创建表CREATE TABLE teacher2( tid int(4) primary key, cid int(4) not null);CREATE TABLE course2( cid int(4) primary key, cname varchar(20));# 测试数据INSERT INTO teacher2 VALUES (1,2);INSERT INTO teacher2 VALUES (2,1);INSERT INTO teacher2 VALUES (3,3);INSERT INTO course2 VALUES (1,&apos;Jsava&apos;);INSERT INTO course2 VALUES (2,&apos;Python&apos;);INSERT INTO course2 VALUES (3,&apos;Kotlin&apos;);COMMIT;# 查询数据SELECT * FROM teacher2 t LEFT OUTER JOIN course2 c ON t.cid=c.cid WHERE cname=&apos;Java&apos;;# 增加索引ALTER TABLE teacher2 ADD INDEX index_tea_cid (cid);ALTER TABLE course2 ADD INDEX index_cou_cname (cname); 两张表进行查询时索引添加规则 小表驱动大表 一般情况下左外连接给左表加索引，右外连接给右表加索引 未使用索引时执行情况 左表增加索引执行情况 cname字段增加索引后执行情况 using join buffer：MySQL执行引擎使用了连接缓存 多张表总结 小表驱动大表 索引建立在经常查询的字段上 避免索引失效原则 复合索引，不要跨列或者无序使用（最佳左前缀） 复合索引，尽量使用全索引匹配 不要在索引上进行任何操作（计算，函数，类型转换等） 对于复合索引，如果左边失效，则右侧全部失效 复合索引不能使用不等于（!=或&lt;&gt;）或者is null(is not null ),否则自身及右侧索引全部失效 尽量使用覆盖索引 like尽量以“常量”开头不要以“%”开头，否则索引失效，如果需要使用like %x%,可以使用覆盖索引，但是只能将查询等级提升至index级别 尽量不要使用类型转换 尽量不要使用or，否则索引失效 其他优化方法 exist和in 如果主查询的数据集大，则使用in 如果子查询的数据集大，则使用exist exist:将主查询的结放到子查询中进行 条件校验，看子查询中是否有数据，如果有数据则校验成功 in: MySQL两种排序方式 文件排序 扫描有序索引排序 order by 优化 using filesort 双路排序，扫描两次磁盘（1从磁盘中读取排序字段，在buffer缓冲区中对字段进行排序2扫描其他字段） 单路排序（只读取一次全部字段，在buffer中进行排序，如果数据量过大可能会读取多次文件进行排序，调整buffer的容量大小） 增大sort_buffer_size参数的设置 增大max_length_for_sort_data参数的设置 避免select *… 复合索引不要跨列使用 保证全部排序字段的排序一致性（都是升序或者降序） group by优化 实质上是先排序再进行分组，遵照索引建的最佳左前缀 where高于having，能写在where限定的条件就不要去having限定 SQL排查-慢查询日志设置记录慢查询日志MySQL提供的日志记录，用于记录MySQL中响应时间超过阀值的SQL语句 123456789101112131415161718# 检查是否开启慢查询show variables like &apos;%slow_query_log&apos;;# 查看慢查询阀值show variables like &apos;%long_query_time%&apos;;# 设置临时阀值set global long_query_time = 5;# 永久设置[mysqld]long_query_time=5# 临时开启set global slow_query_log = 1;# 永久开启（建议调试时开启正式环境关闭），编辑配置文件/etc/my.cnf[mysqld]slow_query_log=1slow_query_log_file=/var/lib/mysql/localhost-slow.loglong_output=FILE# 查询超过设置阀值的SQL数量show global status like &apos;%slow_queries%&apos;; 查看具体的慢查询SQL语句方式查看自定义的慢查询日志文件通过MySQLdumpslow工具查看慢SQL常用参数 参数 含义 s 按照何种方式排序 c 访问次数 l 锁定时间 r 逆序 t 返回记录数 al 平均锁定时间 ar 平均返回记录数 at 平均查询时间 g 正则匹配 常用命令123456# 获取返回记录最多的三个SQLmysqldumpslow -s r -t 3 /var/lib/mysql/slow.log# 获取访问次数最多的三个SQLmysqldumpslow -s c -t 3 /var/lib/mysql/slow.log# 按照时间排序，前十条包含left join查询语句的SQLmysqldumpslow -s t -t 10 -g "left join" /var/lib/mysql/slow.log | more show profile作用用来分析当前会话中语句执行的资源消耗情况 如何做模拟海量数据 通过存储函数与存储过程 语法123456789# 查看profile属性show variables like &apos;%profiling%&apos;;# 会记录所有profiling打开之后的查询SQL所花费的时间（只能看到全部SQL查询话费的时间）show profiles;# 查看硬件各部分在执行SQL时花费的时间show profile all # 诊断SQLshow profile cpu,block io for query 问题queryID 全局查询日志相关命令123456# 开启set global general_log=1;# set global log_output=&apos;TABLE&apos;;# 查询SELECT * FROM mysql.general_log; SQL优化建议一般性建议 对于单键索引，尽量选择针对当前query过滤性更好的索引 在选择组合索引的时候，当前query中过滤性最好的字段在索引字段顺序 中，位置越靠前越好 在选择组合索引时，尽量选择可以能够包含当前query中的where字句中更多字段的索引 尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的 SQL优化的方案总结开启慢查询并查看日志explain+慢SQL分析show profile查询SQL在MySQL服务器的执行细节与生命周期情况SQL数据库服务器的参数调优]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>SQL</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础之事务]]></title>
    <url>%2F2017%2F06%2F01%2Fdatabase%2FMySQL%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E4%B9%8B%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[什么是事务事务是需要在同一个处理单元中执行的一系列更新处理的集合。通过使用事务，可以对数据库中的数据更新处理的提交和取消进行管理。 相关语法123456789101112131415START TRANSACTION DML语句1; DML语句2; DML语句3;COMMIT;# 启动事务 start transaction# 事务提交 commit# 事务回滚 rollback# savepoint 控制回滚的位置 SAVEPOINT identifier ROLLBACK [WORK] TO [SAVEPOINT] identifier 如果没有显式启动事务，每个语句都会当作一个默认的事务，其执行完成会被自动提交 1234# 查看是否开启自动提交（开启自动提交时值为1）select @@global.autocommit# 关闭自动提交set global autocommit = 0 注意 关闭自动提交，请记得手动启动事务，手动提交事务 事务的特性原子性(Atomicity)原子性是指事务中包含的操作被看作是一个整体的业务单元，在事务结束时，其中所包含的更新处理要么全部执行，要么完全不执行。 一致性(Consistency)一致性指的是事务在完成时，必须使所有的数据都保持一致状态，在数据库中所有的修改都基于事务，保证了数据的完整性。 隔离性(Isolation)隔离性指的是保证不同事务之间互不干扰的特性。该特性保证了事务之间不会互相嵌套。此外，在某个事务中进行的更改，在该事务结束之前，对其他事务而言是不可见的。通过选择数据库定义的隔离级别，可以在不同程度上压制丢失更新的发生。 持久性(Durability)持久性也可以称为耐久性，指的是在事务（不论是提交还是回滚）结束后，DBMS 能够保证该时间点的数据状态会被保存（保存到磁盘等）的特性。 事务的隔离级别隔离级别 隔离级别 脏读 可重复读 幻读 READ UNCOMMITTED √ √ √ READ COMMITTED × √ √ REPEATABLE READ（DEAFULT） × × √ SERIALIZABLE × × × 查看数据库的隔离级别1show global variables like &apos;%iso%&apos;; 选择隔离级别的时候，既需要考虑数据的一致性避免脏数据，又要考虑系统性能的问题。更高的隔离级别意味着能够更好的保证数据的一致性，但是也会因为加锁而导致程序性能的下降。 如何克服数据不一致与性能下降的问题 采用乐观锁 使用Redis作为数据载体同步库存到MySQL中 Spring事务源码定义 123456789101112131415161718192021222324252627@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface Transactional &#123; @AliasFor("transactionManager") String value() default ""; @AliasFor("value") String transactionManager() default ""; // 事务的传播行为 Propagation propagation() default Propagation.REQUIRED; // 事务的隔离级别 Isolation isolation() default Isolation.DEFAULT; // 超时时间设置 int timeout() default -1; // 是否只读 boolean readOnly() default false; // 指定需要回滚的异常 Class&lt;? extends Throwable&gt;[] rollbackFor() default &#123;&#125;; String[] rollbackForClassName() default &#123;&#125;; // 指定不需要回滚的异常 Class&lt;? extends Throwable&gt;[] noRollbackFor() default &#123;&#125;; String[] noRollbackForClassName() default &#123;&#125;;&#125; 事务的隔离级别12345678910111213141516171819202122public enum Isolation &#123; // 采用数据库默认的隔离级别 DEFAULT(-1), // 读未提交 READ_UNCOMMITTED(1), // 读已提交 READ_COMMITTED(2), // 可重复读 REPEATABLE_READ(4), // 串行化 SERIALIZABLE(8); private final int value; private Isolation(int value) &#123; this.value = value; &#125; public int value() &#123; return this.value; &#125;&#125; 事务的传播行为事务的传播行为指的是方法之间调用事务采取的策略问题。 1234567891011121314151617181920212223242526public enum Propagation &#123; // 默认传播行为，需要事务 REQUIRED(0), // 支持事务 SUPPORTS(1), // 必须使用事务，没有事务时抛出异常 MANDATORY(2), // 无论当前事务是否存在都会新建事务运行方法 REQUIRES_NEW(3), // 不支持事务，存在事务时挂起事务运行 NOT_SUPPORTED(4), // 不支持事务，存在事务时直接抛出异常 NEVER(5), // 在当前方法调用子方法时，如果子方法发生异常，只会回滚子方法，而不会回滚当前方法的事务 NESTED(6); private final int value; private Propagation(int value) &#123; this.value = value; &#125; public int value() &#123; return this.value; &#125;&#125; 项目实例使用NESTED表示延用同一事务，这样在外围事务发生回滚时子事务也会被回滚，而如果使用REQUIRES_NEW表示新建事务，这种情况下即使外围事务发生异常对子事务并没有影响。 在用户注册时，如果想要在用户注册成功后发放部分优惠券等操作，则应该使用NESTED延用外围事务，否则如果用户新增失败发生回滚而优惠券表中存在的记录就是脏数据 另外像记录日志的方法可以使用NOT_SUPPORTED，将外围事务挂起后进行记录]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>事务</tag>
      </tags>
  </entry>
</search>
